{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62bd74ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from mutation import *\n",
    "from crossover import *\n",
    "from rmp import *\n",
    "from mfea import *\n",
    "from task import *\n",
    "from llm import *\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a396532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv()\n",
    "\n",
    "# GPT_API_KEY = os.getenv(\"GPT_API_KEY\")\n",
    "\n",
    "# llm = GPTModel(GPT_API_KEY, \"gpt-3.5-turbo-0125\", 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d98d09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cec2017_tasks = get_2_tasks(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70978029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization:\n",
      "Task 0:\n",
      "Best Fitness: 34.629614718853325\n",
      "Mean Fitness: 43.33345570014081\n",
      "\n",
      "Task 1:\n",
      "Best Fitness: 28389.17824247567\n",
      "Mean Fitness: 41755.594589612476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_indis_per_task = 50\n",
    "indi_len = 50\n",
    "mutation = PolynomialMutation(5, 0.02)\n",
    "crossover = SBXCrossover(mutation, eta=20)\n",
    "# crossover = BLXCrossover()\n",
    "rmp = AdaptiveRMPMatrix(rmp_pop_size=4, num_gen=3, pc=0.8, pm=0.1)\n",
    "\n",
    "np.random.seed(0)\n",
    "amfea = AMFEA(num_indis_per_task, indi_len, cec2017_tasks, crossover, mutation, rmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a667e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating strategy\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the mean vectors of each pair of tasks, and adjust RMP values inversely proportional to the distance.\n",
      "Compare the variance vectors of each pair of tasks using a statistical test such as ANOVA, and adjust RMP values based on the level of significance.\n",
      "Cluster tasks based on the similarity of their population distributions using a clustering algorithm, and adjust RMP values based on the cluster membership of each task.\n",
      "Calculate the correlation coefficient between the mean and variance vectors of each pair of tasks, and adjust RMP values based on the strength and direction of the correlation.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.stats import f_oneway\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if i == j:\n",
      "                rmp_matrix[i][j] = 1.0\n",
      "            else:\n",
      "                euclidean_dist = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "                rmp_matrix[i][j] = 1 / (1 + euclidean_dist)\n",
      "                rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "                \n",
      "                _, p_value = f_oneway(pop_variance[i], pop_variance[j])\n",
      "                if p_value < 0.05:\n",
      "                    rmp_matrix[i][j] *= 0.5\n",
      "                    rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.         0.70769761]\n",
      " [0.70769761 1.        ]]\n",
      "Better off count: 98\n",
      "Performance: 49.0\n",
      "Creating strategy\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the mean vectors of each task. Adjust RMP values inversely proportional to the distance, assigning higher probabilities to more similar tasks.\n",
      "Analyze the variance matrix to identify tasks with significantly different variances. Increase RMP values for task pairs with similar variances and decrease for those with large discrepancies.\n",
      "Consider the correlation between mean vectors and variance matrices for each task. Increase RMP values for tasks with high mean correlation and low variance correlation, and vice versa.\n",
      "Cluster tasks based on their population statistics using a hierarchical clustering algorithm. Adjust RMP values based on the cluster membership of each task, assigning higher probabilities to tasks within the same cluster.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.spatial.distance import pdist, squareform\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    mean_distances = squareform(pdist(pop_mean))\n",
      "    variance_diff = np.abs(pop_variance[:, np.newaxis] - pop_variance)\n",
      "    mean_corr = np.corrcoef(pop_mean)\n",
      "    variance_corr = np.corrcoef(pop_variance)\n",
      "    \n",
      "    rmp_matrix = np.ones((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_matrix[i][j] = rmp_matrix[j][i] = 1 / (1 + mean_distances[i][j])\n",
      "            rmp_matrix[i][j] *= 1 / (1 + variance_diff[i][j])\n",
      "            rmp_matrix[i][j] *= (1 + mean_corr[i][j]) / (1 + variance_corr[i][j])\n",
      "    \n",
      "    return rmp_matrix\n",
      "Error in creating RMP matrix: setting an array element with a sequence.\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Better off count: 67\n",
      "Performance: 33.5\n",
      "Creating strategy\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the mean vectors of each task to determine the level of dissimilarity. Adjust RMP values inversely proportional to this distance.\n",
      "Analyze the variance matrices to identify tasks with significantly different spread or diversity. Increase RMP values for task pairs with high diversity to promote exploration.\n",
      "Utilize statistical measures such as correlation coefficients or covariance matrices to quantify the relationship between tasks. Adjust RMP values based on the strength and direction of these relationships.\n",
      "Consider the impact of task complexity on population distributions. Increase RMP values for pairs involving more complex tasks to facilitate knowledge transfer and information sharing.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if i == j:\n",
      "                rmp_matrix[i][j] = 1.0\n",
      "            else:\n",
      "                dist = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "                rmp_matrix[i][j] = 1 / (1 + dist)\n",
      "                rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if i != j:\n",
      "                if np.sum(pop_variance[i]) > np.sum(pop_variance[j]):\n",
      "                    rmp_matrix[i][j] += 0.1\n",
      "                    rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.         0.80769761]\n",
      " [0.80769761 1.        ]]\n",
      "Better off count: 91\n",
      "Performance: 45.5\n",
      "Creating strategy\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the mean vectors of each pair of tasks. Adjust RMP values inversely proportional to the distance, giving higher probabilities to tasks with closer mean vectors.\n",
      "Analyze the variance matrices to identify tasks with significantly different spread or diversity. Increase RMP values for task pairs with high diversity to encourage exploration between tasks.\n",
      "Compare the standard deviations of the population distributions for each task. Adjust RMP values based on the relative magnitude of standard deviations, favoring pairs with more similar spread.\n",
      "Utilize a statistical measure such as the Mahalanobis distance to account for both mean and variance differences between tasks. Adjust RMP values based on the Mahalanobis distance to balance similarity in distribution shape and position.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            distance = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "            similarity = 1 / (1 + distance)\n",
      "            rmp_matrix[i][j] = similarity\n",
      "            rmp_matrix[j][i] = similarity\n",
      "    \n",
      "    max_variance = np.max(pop_variance, axis=1)\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            diversity = np.abs(pop_variance[i] - pop_variance[j]) / max_variance\n",
      "            diversity_factor = np.mean(diversity)\n",
      "            rmp_matrix[i][j] *= diversity_factor\n",
      "            rmp_matrix[j][i] *= diversity_factor\n",
      "    \n",
      "    std_dev = np.std(pop_mean, axis=1)\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            std_dev_diff = np.abs(std_dev[i] - std_dev[j]) / np.max(std_dev)\n",
      "            std_dev_factor = 1 - std_dev_diff\n",
      "            rmp_matrix[i][j] *= std_dev_factor\n",
      "            rmp_matrix[j][i] *= std_dev_factor\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            mean_diff = pop_mean[i] - pop_mean[j]\n",
      "            cov_mat = np.diag(pop_variance[i] + pop_variance[j])\n",
      "            mahalanobis_dist = np.sqrt(np.dot(np.dot(mean_diff, np.linalg.inv(cov_mat)), mean_diff))\n",
      "            mahalanobis_factor = 1 / (1 + mahalanobis_dist)\n",
      "            rmp_matrix[i][j] *= mahalanobis_factor\n",
      "            rmp_matrix[j][i] *= mahalanobis_factor\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "Error in creating RMP matrix: operands could not be broadcast together with shapes (50,) (2,) \n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Better off count: 79\n",
      "Performance: 39.5\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the cosine similarity between the mean vectors of each pair of tasks. Adjust RMP values based on the cosine similarity, assigning higher probabilities to task pairs with higher similarity.\n",
      "Perform a t-test on the population variances of each pair of tasks. Increase RMP values for task pairs with statistically similar variances and decrease for those with significant differences.\n",
      "Cluster tasks based on the Euclidean distance between their mean vectors using a k-means clustering algorithm. Adjust RMP values based on the cluster membership of each task, assigning higher probabilities to tasks within the same cluster.\n",
      "Calculate the Mahalanobis distance between the mean vectors of each pair of tasks using the covariance matrix of the population. Adjust RMP values based on the Mahalanobis distance, assigning higher probabilities to task pairs with lower distance.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.spatial.distance import mahalanobis\n",
      "from scipy.stats import t\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    def cosine_similarity(a, b):\n",
      "        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
      "\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            cosine_sim = cosine_similarity(pop_mean[i], pop_mean[j])\n",
      "            t_stat, _ = ttest_ind(pop_variance[i], pop_variance[j])\n",
      "            mahalanobis_dist = mahalanobis(pop_mean[i], pop_mean[j], np.linalg.inv(np.cov(pop_mean.T)))\n",
      "            \n",
      "            if i == j:\n",
      "                RMP[i][j] = 1.0\n",
      "            else:\n",
      "                RMP[i][j] = cosine_sim * (1 - t_stat) * mahalanobis_dist\n",
      "                RMP[j][i] = RMP[i][j]\n",
      "    \n",
      "    return RMP\n",
      "Error in creating RMP matrix: name 'ttest_ind' is not defined\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Better off count: 58\n",
      "Performance: 28.999999999999996\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the cosine dissimilarity between the mean vectors of each pair of tasks. Adjust RMP values based on the cosine dissimilarity, assigning higher probabilities to task pairs with lower dissimilarity.\n",
      "Perform a t-test on the population variances of each pair of tasks. Increase RMP values for task pairs with statistically different variances and decrease for those with similar variances.\n",
      "Cluster tasks based on the Euclidean distance between their mean vectors using a hierarchical clustering algorithm. Adjust RMP values based on the cluster membership of each task, assigning lower probabilities to tasks within the same cluster.\n",
      "Calculate the Mahalanobis distance between the mean vectors of each pair of tasks using the covariance matrix of the population. Adjust RMP values based on the Mahalanobis distance, assigning higher probabilities to task pairs with higher distance.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.spatial.distance import cosine, euclidean, mahalanobis\n",
      "from scipy.stats import ttest_ind\n",
      "from scipy.cluster.hierarchy import linkage, fcluster\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            cosine_similarity = 1 - cosine(pop_mean[i], pop_mean[j])\n",
      "            t_stat, _ = ttest_ind(pop_variance[i], pop_variance[j])\n",
      "            euclidean_distance = euclidean(pop_mean[i], pop_mean[j])\n",
      "            mahalanobis_distance = mahalanobis(pop_mean[i], pop_mean[j], np.linalg.inv(np.cov(pop_mean.T)))\n",
      "            \n",
      "            rmp_matrix[i][j] = rmp_matrix[j][i] = (cosine_similarity + 1 - t_stat + 1/(1 + euclidean_distance) + mahalanobis_distance) / 4\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "Fixed RMP matrix still invalid, using default\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Better off count: 61\n",
      "Performance: 30.5\n",
      "Crossover...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\scipy\\spatial\\distance.py:1035: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(m)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the cosine similarity between the mean vectors of each pair of tasks. Adjust RMP values based on the angle between the vectors, increasing values for more similar tasks and decreasing values for more dissimilar tasks.\n",
      "Perform a hierarchical clustering analysis on the population distributions of tasks. Adjust RMP values based on the resulting dendrogram, increasing values for tasks within the same cluster and decreasing values for tasks in different clusters.\n",
      "Utilize a Mahalanobis distance metric to quantify the multivariate distance between tasks' population distributions. Adjust RMP values inversely proportional to this distance, giving higher values to tasks with closer distributions.\n",
      "Apply a Kolmogorov-Smirnov test to compare the cumulative distribution functions of tasks. Adjust RMP values based on the test statistic, increasing values for tasks with similar distributions and decreasing values for tasks with significant differences.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.spatial.distance import mahalanobis\n",
      "from scipy.cluster.hierarchy import linkage, dendrogram\n",
      "from scipy.stats import ks_2samp\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            cosine_similarity = np.dot(pop_mean[i], pop_mean[j]) / (np.linalg.norm(pop_mean[i]) * np.linalg.norm(pop_mean[j]))\n",
      "            rmp_matrix[i][j] = rmp_matrix[j][i] = cosine_similarity\n",
      "\n",
      "    linkage_matrix = linkage(pop_mean, method='complete')\n",
      "    dendro = dendrogram(linkage_matrix, no_plot=True)\n",
      "    clusters = dendro['leaves']\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            mahalanobis_distance = mahalanobis(pop_mean[i], pop_mean[j], np.linalg.inv(np.diag(pop_variance[i])))\n",
      "            rmp_matrix[i][j] = rmp_matrix[j][i] = 1 / (1 + mahalanobis_distance)\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            ks_statistic, _ = ks_2samp(pop_mean[i], pop_mean[j])\n",
      "            rmp_matrix[i][j] = rmp_matrix[j][i] = rmp_matrix[i][j] * (1 + ks_statistic)\n",
      "\n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "\n",
      "    return rmp_matrix\n",
      "[[1.        0.4511488]\n",
      " [0.4511488 1.       ]]\n",
      "Better off count: 71\n",
      "Performance: 35.5\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the mean vectors of each pair of tasks. Adjust RMP values based on the distance, increasing values for more dissimilar tasks and decreasing values for more similar tasks.\n",
      "Perform a principal component analysis on the population distributions of tasks. Adjust RMP values based on the principal components, increasing values for tasks with distinct distributions and decreasing values for tasks with similar distributions.\n",
      "Utilize a Manhattan distance metric to quantify the distance between tasks' population distributions. Adjust RMP values directly proportional to this distance, giving higher values to tasks with more distant distributions.\n",
      "Apply a Chi-Square test to compare the frequency distributions of tasks. Adjust RMP values based on the test statistic, increasing values for tasks with significant distributional differences and decreasing values for tasks with similar distributions.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.spatial.distance import pdist, squareform\n",
      "from scipy.stats import chi2_contingency\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.ones((task_count, task_count))\n",
      "    \n",
      "    euclidean_distances = squareform(pdist(pop_mean, metric='euclidean'))\n",
      "    pca_components = np.linalg.svd(pop_variance, full_matrices=False)[2]\n",
      "    manhattan_distances = squareform(pdist(pop_mean, metric='cityblock'))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_matrix[i][j] = np.exp(-euclidean_distances[i][j]) * np.dot(pca_components[i], pca_components[j]) * np.exp(-manhattan_distances[i][j]) * chi2_contingency([pop_mean[i], pop_mean[j]])[0]\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.00000000e+00 1.24767735e-18]\n",
      " [1.24767735e-18 1.00000000e+00]]\n",
      "Better off count: 36\n",
      "Performance: 18.0\n",
      "End LLM\n",
      "Best strategy:\n",
      " ['Calculate the Euclidean distance between the mean vectors of each pair of tasks, and adjust RMP values inversely proportional to the distance.', 'Compare the variance vectors of each pair of tasks using a statistical test such as ANOVA, and adjust RMP values based on the level of significance.', 'Cluster tasks based on the similarity of their population distributions using a clustering algorithm, and adjust RMP values based on the cluster membership of each task.', 'Calculate the correlation coefficient between the mean and variance vectors of each pair of tasks, and adjust RMP values based on the strength and direction of the correlation.']\n",
      "Best performance: 49.0\n",
      "Best RMP matrix:\n",
      " [[1.         0.70769761]\n",
      " [0.70769761 1.        ]]\n",
      "-------------------------------------------------\n",
      "Gen 0\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 33.553731670437905, Avg: 38.27132778373407\n",
      "Task 1, Best: 28230.773879799726, Avg: 36669.84314754264\n",
      "Time taken each gen: 61.5037 seconds\n",
      "\n",
      "Gen 10\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 18.90350177415848, Avg: 19.93714833023224\n",
      "Task 1, Best: 16529.31994172481, Avg: 19008.530904698397\n",
      "Time taken each gen: 0.0030 seconds\n",
      "\n",
      "Gen 20\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 12.40555984941069, Avg: 13.497256240225152\n",
      "Task 1, Best: 11652.039555076159, Avg: 12999.201356197675\n",
      "Time taken each gen: 0.0056 seconds\n",
      "\n",
      "Gen 30\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 10.800323035359423, Avg: 11.071510856338922\n",
      "Task 1, Best: 9818.050573588254, Avg: 10501.975363332494\n",
      "Time taken each gen: 0.0036 seconds\n",
      "\n",
      "Gen 40\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 8.707413117591704, Avg: 9.006866505935024\n",
      "Task 1, Best: 8219.847258585916, Avg: 8484.646984838855\n",
      "Time taken each gen: 0.0054 seconds\n",
      "\n",
      "Gen 50\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 8.15544366547948, Avg: 8.219467073203866\n",
      "Task 1, Best: 7598.776432939171, Avg: 7702.622642787743\n",
      "Time taken each gen: 0.0030 seconds\n",
      "\n",
      "Gen 60\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 7.267634495273992, Avg: 7.421471919658452\n",
      "Task 1, Best: 6700.894600418847, Avg: 6893.365044748985\n",
      "Time taken each gen: 0.0045 seconds\n",
      "\n",
      "Gen 70\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 6.326148033655019, Avg: 6.5228154261197355\n",
      "Task 1, Best: 5888.375931090492, Avg: 6004.523566604494\n",
      "Time taken each gen: 0.0037 seconds\n",
      "\n",
      "Gen 80\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 5.6584531666505375, Avg: 5.847689521694689\n",
      "Task 1, Best: 5245.0668421503615, Avg: 5364.8052090768415\n",
      "Time taken each gen: 0.0096 seconds\n",
      "\n",
      "Gen 90\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 4.835880169157479, Avg: 5.096276535507251\n",
      "Task 1, Best: 4284.917331376421, Avg: 4601.989755673122\n",
      "Time taken each gen: 0.0030 seconds\n",
      "\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the cosine similarity between mean vectors of each pair of tasks. Adjust RMP values proportionally to the similarity, assigning higher probabilities to more similar tasks.\n",
      "Analyze the covariance matrices to identify tasks with similar or dissimilar spread in different dimensions. Increase RMP values for task pairs with similar covariance structures and decrease for those with large discrepancies.\n",
      "Compute the Kullback-Leibler divergence between the probability distributions of each pair of tasks. Adjust RMP values based on the divergence, favoring pairs with lower KL divergence to encourage exploration between tasks with similar distributions.\n",
      "Utilize a dimensionality reduction technique such as PCA to extract underlying patterns in the population statistics. Adjust RMP values based on the principal components to promote mating between tasks that exhibit similar patterns in the search space.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if i == j:\n",
      "                rmp_matrix[i][j] = 1.0\n",
      "            else:\n",
      "                mean_sim = np.dot(pop_mean[i], pop_mean[j]) / (np.linalg.norm(pop_mean[i]) * np.linalg.norm(pop_mean[j]))\n",
      "                var_sim = np.exp(-np.sum(np.square(pop_variance[i] - pop_variance[j])))\n",
      "                kl_div = np.sum(pop_variance[i] * np.log(pop_variance[i] / pop_variance[j]))\n",
      "                rmp_matrix[i][j] = mean_sim * var_sim * kl_div\n",
      "                rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.         0.02484228]\n",
      " [0.02484228 1.        ]]\n",
      "Better off count: 41\n",
      "Performance: 20.5\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Analyze the cosine similarity between mean vectors of each pair of tasks. Adjust RMP values inversely proportional to the similarity, assigning higher probabilities to more dissimilar tasks.\n",
      "Examine the covariance matrices to identify tasks with dissimilar spread in different dimensions. Increase RMP values for task pairs with dissimilar covariance structures and decrease for those with similar ones.\n",
      "Compute the Kullback-Leibler divergence between the probability distributions of each pair of tasks. Adjust RMP values based on the divergence, favoring pairs with higher KL divergence to encourage exploration between tasks with dissimilar distributions.\n",
      "Utilize a dimensionality reduction technique such as PCA to extract underlying patterns in the population statistics. Adjust RMP values based on the principal components to promote mating between tasks that exhibit dissimilar patterns in the search space.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sklearn.metrics import pairwise_distances\n",
      "from scipy.stats import entropy\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if i == j:\n",
      "                RMP[i][j] = 1.0\n",
      "            else:\n",
      "                cos_sim = cosine_similarity(pop_mean[i].reshape(1, -1), pop_mean[j].reshape(1, -1))[0][0]\n",
      "                cov_sim = np.mean(pairwise_distances(pop_variance[i].reshape(1, -1), pop_variance[j].reshape(1, -1)))\n",
      "                kl_div = entropy(pop_mean[i], pop_mean[j])\n",
      "                RMP[i][j] = 1 - (cos_sim + cov_sim + kl_div) / 3\n",
      "                RMP[j][i] = RMP[i][j]\n",
      "    return RMP\n",
      "[[1.         0.66485771]\n",
      " [0.66485771 1.        ]]\n",
      "Better off count: 64\n",
      "Performance: 32.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the cosine similarity between the mean vectors of each task. Adjust RMP values directly proportional to the similarity, assigning higher probabilities to more similar tasks.\n",
      "Analyze the Mahalanobis distance between the variance matrices of tasks. Increase RMP values for task pairs with similar spread and decrease for those with large discrepancies.\n",
      "Consider the skewness and kurtosis of population distributions for each task. Adjust RMP values based on the shape of the distributions, assigning higher probabilities to tasks with similar distribution patterns.\n",
      "Cluster tasks based on the shape of their distribution using a density-based clustering algorithm. Adjust RMP values based on the cluster membership of each task, assigning higher probabilities to tasks within the same cluster.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.spatial.distance import mahalanobis\n",
      "from scipy.stats import skew, kurtosis\n",
      "from sklearn.cluster import DBSCAN\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            mean_similarity = np.dot(pop_mean[i], pop_mean[j]) / (np.linalg.norm(pop_mean[i]) * np.linalg.norm(pop_mean[j]))\n",
      "            var_distance = mahalanobis(pop_variance[i], pop_variance[j])\n",
      "            skew_diff = np.abs(skew(pop_mean[i]) - skew(pop_mean[j]))\n",
      "            kurt_diff = np.abs(kurtosis(pop_mean[i]) - kurtosis(pop_mean[j]))\n",
      "            \n",
      "            rmp_matrix[i][j] = mean_similarity * (1 - var_distance) * (1 - skew_diff) * (1 - kurt_diff)\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    clustering = DBSCAN(eps=0.5, min_samples=2).fit(pop_mean)\n",
      "    labels = clustering.labels_\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if labels[i] == labels[j]:\n",
      "                rmp_matrix[i][j] *= 1.2\n",
      "                rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "            else:\n",
      "                rmp_matrix[i][j] *= 0.8\n",
      "                rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "Error in creating RMP matrix: mahalanobis() missing 1 required positional argument: 'VI'\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Better off count: 40\n",
      "Performance: 20.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Focus on maximizing variance in RMP values between tasks, assigning higher probabilities to task pairs with significantly different spread and decreasing probabilities for more similar tasks.\n",
      "Consider the Euclidean distance between the mean vectors of tasks. Decrease RMP values for tasks with similar average positions in the search space and increase for those with more diverse mean vectors.\n",
      "Analyze the kurtosis and skewness of population distributions for each task. Adjust RMP values based on the shape of the distributions, assigning lower probabilities to tasks with similar distribution patterns.\n",
      "Cluster tasks based on the shape of their distribution using a centroid-based clustering algorithm. Adjust RMP values based on the cluster membership of each task, assigning lower probabilities to tasks within the same cluster.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if i == j:\n",
      "                RMP[i][j] = 1.0\n",
      "            else:\n",
      "                mean_distance = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "                variance_distance = np.linalg.norm(pop_variance[i] - pop_variance[j])\n",
      "                RMP[i][j] = 1 / (1 + mean_distance + variance_distance)\n",
      "                RMP[j][i] = RMP[i][j]\n",
      "    return RMP\n",
      "[[1.         0.89549812]\n",
      " [0.89549812 1.        ]]\n",
      "Better off count: 76\n",
      "Performance: 38.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the cosine similarity between the mean vectors of each pair of tasks. Adjust RMP values based on the cosine similarity, assigning higher probabilities to task pairs with more similar mean vectors.\n",
      "Analyze the covariance matrices of population distributions for each task. Adjust RMP values based on the relative magnitude of covariances, favoring pairs with more diverse spread.\n",
      "Cluster tasks based on the variance of their population distributions using a density-based clustering algorithm. Adjust RMP values based on the cluster density of each task, assigning lower probabilities to tasks within dense clusters.\n",
      "Utilize a multidimensional scaling technique to visualize the similarity between tasks in a lower-dimensional space. Adjust RMP values based on the pairwise distances in the reduced space, favoring task pairs with more dissimilar distribution patterns.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sklearn.cluster import DBSCAN\n",
      "from sklearn.manifold import MDS\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            cos_sim = cosine_similarity(pop_mean[i].reshape(1, -1), pop_mean[j].reshape(1, -1))[0][0]\n",
      "            var_ratio = np.sum(pop_variance[i]) / np.sum(pop_variance[j])\n",
      "            \n",
      "            rmp_matrix[i][j] = cos_sim + 1 - var_ratio\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    clustering = DBSCAN(eps=0.5, min_samples=2).fit(pop_variance)\n",
      "    labels = clustering.labels_\n",
      "    unique_labels = np.unique(labels)\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if labels[i] == labels[j]:\n",
      "                rmp_matrix[i][j] *= 0.5\n",
      "                rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    embedding = MDS(n_components=2, dissimilarity='precomputed')\n",
      "    dist_matrix = 1 - np.abs(cosine_similarity(pop_mean))\n",
      "    reduced_dist = embedding.fit_transform(dist_matrix)\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            rmp_matrix[i][j] *= np.linalg.norm(reduced_dist[i] - reduced_dist[j])\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    rmp_matrix = np.clip(rmp_matrix, 0, 1)\n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.00000000e+00 3.54479369e-04]\n",
      " [3.54479369e-04 1.00000000e+00]]\n",
      "Better off count: 32\n",
      "Performance: 16.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Instead of favoring task pairs with more similar mean vectors, prioritize task pairs with more dissimilar mean vectors when adjusting RMP values.\n",
      "Instead of favoring pairs with more diverse spread, prioritize pairs with less diverse spread when adjusting RMP values based on covariance matrices.\n",
      "Instead of assigning lower probabilities to tasks within dense clusters, assign higher probabilities to tasks within dense clusters when adjusting RMP values based on task clustering.\n",
      "Instead of favoring task pairs with more dissimilar distribution patterns, favor task pairs with more similar distribution patterns when adjusting RMP values based on pairwise distances in reduced space.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            covariance_ij = np.sum((pop_mean[i] - pop_mean[j])**2 / (pop_variance[i] + pop_variance[j]))\n",
      "            RMP[i][j] = np.exp(-covariance_ij)\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    \n",
      "    np.fill_diagonal(RMP, 1.0)\n",
      "    \n",
      "    return RMP\n",
      "[[1.000000e+00 1.495905e-08]\n",
      " [1.495905e-08 1.000000e+00]]\n",
      "Better off count: 38\n",
      "Performance: 19.0\n",
      "End LLM\n",
      "Best strategy:\n",
      " ['Calculate the Euclidean distance between the mean vectors of each pair of tasks, and adjust RMP values inversely proportional to the distance.', 'Compare the variance vectors of each pair of tasks using a statistical test such as ANOVA, and adjust RMP values based on the level of significance.', 'Cluster tasks based on the similarity of their population distributions using a clustering algorithm, and adjust RMP values based on the cluster membership of each task.', 'Calculate the correlation coefficient between the mean and variance vectors of each pair of tasks, and adjust RMP values based on the strength and direction of the correlation.']\n",
      "Best performance: 49.0\n",
      "Best RMP matrix:\n",
      " [[1.         0.70769761]\n",
      " [0.70769761 1.        ]]\n",
      "-------------------------------------------------\n",
      "Gen 100\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 4.111622522329689, Avg: 4.533839610486864\n",
      "Task 1, Best: 3639.9601345573883, Avg: 4119.523624537772\n",
      "Time taken each gen: 30.1428 seconds\n",
      "\n",
      "Gen 110\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 3.6927209571037256, Avg: 3.7541672199574028\n",
      "Task 1, Best: 3147.738758775589, Avg: 3231.6502863051046\n",
      "Time taken each gen: 0.0025 seconds\n",
      "\n",
      "Gen 120\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 3.3448490731104967, Avg: 3.3709281450362285\n",
      "Task 1, Best: 2752.191332858071, Avg: 2850.4054763659146\n",
      "Time taken each gen: 0.0035 seconds\n",
      "\n",
      "Gen 130\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 3.0343526606215954, Avg: 3.1212797390868467\n",
      "Task 1, Best: 2483.2962538299944, Avg: 2533.5701395160363\n",
      "Time taken each gen: 0.0030 seconds\n",
      "\n",
      "Gen 140\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.7051522821585046, Avg: 2.809881009405812\n",
      "Task 1, Best: 2204.001457140248, Avg: 2352.1471118703757\n",
      "Time taken each gen: 0.0072 seconds\n",
      "\n",
      "Gen 150\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.374759733741508, Avg: 2.4620842683694333\n",
      "Task 1, Best: 1825.749717138957, Avg: 1912.5593470600777\n",
      "Time taken each gen: 0.0030 seconds\n",
      "\n",
      "Gen 160\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.2657036135198627, Avg: 2.2877726943219723\n",
      "Task 1, Best: 1731.40059513791, Avg: 1753.4715740021386\n",
      "Time taken each gen: 0.0030 seconds\n",
      "\n",
      "Gen 170\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 1.9928704423218042, Avg: 2.061546881913047\n",
      "Task 1, Best: 1434.4861222286672, Avg: 1519.4445422046733\n",
      "Time taken each gen: 0.0030 seconds\n",
      "\n",
      "Gen 180\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 1.852191208912418, Avg: 1.950542447907267\n",
      "Task 1, Best: 1287.6065316562813, Avg: 1339.101935374614\n",
      "Time taken each gen: 0.0050 seconds\n",
      "\n",
      "Gen 190\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 1.782660577519193, Avg: 1.8002666666196716\n",
      "Task 1, Best: 1232.2922197961402, Avg: 1249.9398954758117\n",
      "Time taken each gen: 0.0046 seconds\n",
      "\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the cosine similarity between the mean vectors of each pair of tasks and adjust RMP values proportionally to the similarity, favoring pairs with higher similarity.\n",
      "Identify tasks with significantly different variance structures using a statistical test such as Levene's test, and adjust RMP values based on the test results.\n",
      "Utilize a dimensionality reduction technique such as PCA to capture the main patterns of variance within tasks. Adjust RMP values based on the principal components to account for the most important sources of diversity.\n",
      "Cluster tasks based on both mean and variance vectors using a combined clustering algorithm such as K-means with Mahalanobis distance. Adjust RMP values based on the cluster membership and distance within clusters to promote exploration between similar tasks.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.spatial.distance import mahalanobis\n",
      "from scipy.stats import levene\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.cluster import KMeans\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        rmp_matrix[i][i] = 1.0\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            cos_sim = np.dot(pop_mean[i], pop_mean[j]) / (np.linalg.norm(pop_mean[i]) * np.linalg.norm(pop_mean[j]))\n",
      "            rmp_matrix[i][j] = cos_sim\n",
      "            rmp_matrix[j][i] = cos_sim\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            stat, p_value = levene(pop_variance[i], pop_variance[j])\n",
      "            if p_value < 0.05:\n",
      "                rmp_matrix[i][j] *= 0.5\n",
      "                rmp_matrix[j][i] *= 0.5\n",
      "    \n",
      "    pca = PCA(n_components=1)\n",
      "    pca.fit(pop_variance)\n",
      "    principal_components = pca.components_\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_matrix[i][j] *= principal_components[i]\n",
      "            rmp_matrix[j][i] *= principal_components[j]\n",
      "    \n",
      "    combined_data = np.concatenate((pop_mean, pop_variance), axis=1)\n",
      "    kmeans = KMeans(n_clusters=2, metric='mahalanobis', metric_params={'V': np.cov(combined_data.T)}).fit(combined_data)\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            if kmeans.labels_[i] == kmeans.labels_[j]:\n",
      "                rmp_matrix[i][j] *= 1.5\n",
      "                rmp_matrix[j][i] *= 1.5\n",
      "            else:\n",
      "                rmp_matrix[i][j] *= 0.5\n",
      "                rmp_matrix[j][i] *= 0.5\n",
      "    \n",
      "    return rmp_matrix\n",
      "Error in creating RMP matrix: setting an array element with a sequence.\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Better off count: 44\n",
      "Performance: 22.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Focus on maximizing exploration between tasks with the most dissimilar mean vectors, as diversity in mean positions can lead to complementary search directions.\n",
      "Adjust RMP values to favor task pairs with the most distinct variance structures, as this can promote exploration of different regions of the search space.\n",
      "Disregard dimensionality reduction techniques and prioritize maintaining the original diversity within tasks, as reducing dimensions may lead to loss of important variance patterns.\n",
      "Avoid clustering tasks based on mean and variance vectors, as this can limit exploration between tasks with potentially valuable differences in search space distribution.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if i == j:\n",
      "                RMP[i][j] = 1.0\n",
      "            else:\n",
      "                mean_diff = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "                var_diff = np.linalg.norm(pop_variance[i] - pop_variance[j])\n",
      "                RMP[i][j] = np.exp(-mean_diff) * np.exp(-var_diff)\n",
      "                RMP[j][i] = RMP[i][j]\n",
      "    return RMP\n",
      "[[1.         0.97892222]\n",
      " [0.97892222 1.        ]]\n",
      "Better off count: 78\n",
      "Performance: 39.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Compare the cosine similarity between mean vectors of each pair of tasks. Adjust RMP values inversely proportional to the cosine similarity, giving higher probabilities to tasks with more similar mean vectors.\n",
      "Analyze the covariance matrices to identify tasks with significantly different spread or diversity. Increase RMP values for task pairs with high covariance differences to encourage exploration between tasks.\n",
      "Utilize multidimensional scaling to visualize the relationships between tasks based on mean and variance vectors. Adjust RMP values based on the distances in the MDS plot to promote exploration between tasks that are more distant in the visualization.\n",
      "Consider the correlation coefficients between dimensions within each task. Adjust RMP values based on the average correlation coefficients across tasks, favoring pairs with more similar internal dimension relationships.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    def cosine_similarity(v1, v2):\n",
      "        return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
      "\n",
      "    def adjust_rmp_values(rmp_matrix, task1, task2, value):\n",
      "        rmp_matrix[task1][task2] = value\n",
      "        rmp_matrix[task2][task1] = value\n",
      "\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "\n",
      "    for i in range(task_count):\n",
      "        rmp_matrix[i][i] = 1.0\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            cosine_sim = cosine_similarity(pop_mean[i], pop_mean[j])\n",
      "            similarity_factor = 1 - cosine_sim\n",
      "            adjust_rmp_values(rmp_matrix, i, j, similarity_factor)\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            cov_diff = np.linalg.norm(pop_variance[i] - pop_variance[j])\n",
      "            if cov_diff > 0:\n",
      "                rmp_matrix[i][j] += cov_diff\n",
      "                rmp_matrix[j][i] += cov_diff\n",
      "\n",
      "    mds_distances = np.linalg.norm(pop_mean[:, np.newaxis] - pop_mean, axis=2)\n",
      "    max_dist = np.max(mds_distances)\n",
      "    mds_distances /= max_dist\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            dist_factor = 1 - mds_distances[i][j]\n",
      "            adjust_rmp_values(rmp_matrix, i, j, dist_factor)\n",
      "\n",
      "    avg_corr = np.mean([np.corrcoef(pop_mean[i].T) for i in range(task_count)])\n",
      "    corr_factor = 1 - avg_corr\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            adjust_rmp_values(rmp_matrix, i, j, corr_factor)\n",
      "\n",
      "    return rmp_matrix\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "Better off count: 33\n",
      "Performance: 16.5\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Evaluate the Euclidean distance between mean vectors of each pair of tasks. Adjust RMP values directly proportional to the distance, giving higher probabilities to tasks with more dissimilar mean vectors.\n",
      "Analyze the covariance matrices to identify tasks with similar spread or diversity. Increase RMP values for task pairs with low covariance differences to encourage exploitation within tasks.\n",
      "Utilize multidimensional scaling to visualize the relationships between tasks based on mean and variance vectors. Adjust RMP values based on the distances in the MDS plot to promote exploitation between tasks that are more closely clustered in the visualization.\n",
      "Consider the correlation coefficients between dimensions within each task. Adjust RMP values based on the average correlation coefficients across tasks, favoring pairs with more dissimilar internal dimension relationships.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    def euclidean_distance(vec1, vec2):\n",
      "        return np.linalg.norm(vec1 - vec2)\n",
      "\n",
      "    def normalize_matrix(matrix):\n",
      "        return matrix / np.sum(matrix)\n",
      "\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            mean_distance = euclidean_distance(pop_mean[i], pop_mean[j])\n",
      "            var_distance = np.linalg.norm(pop_variance[i] - pop_variance[j])\n",
      "            rmp_matrix[i][j] = rmp_matrix[j][i] = 1 / (1 + mean_distance + var_distance)\n",
      "\n",
      "    return normalize_matrix(rmp_matrix)\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1.         0.24736518]\n",
      " [0.24736518 1.        ]]\n",
      "Better off count: 46\n",
      "Performance: 23.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the cosine similarity between the mean vectors of each pair of tasks, and adjust RMP values proportional to the similarity.\n",
      "Perform a cluster analysis on the population variance vectors to group tasks with similar spread together. Adjust RMP values based on the cluster membership of each task pair.\n",
      "Use the Mahalanobis distance between the mean vectors of tasks to quantify the dissimilarity in distribution. Adjust RMP values inversely proportional to this distance.\n",
      "Apply a kernel density estimation to estimate the probability density function of each task's population distribution. Adjust RMP values based on the overlap or dissimilarity of these distributions.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sklearn.cluster import KMeans\n",
      "from scipy.spatial.distance import mahalanobis\n",
      "from sklearn.neighbors import KernelDensity\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    # Calculate cosine similarity between mean vectors\n",
      "    cos_sim = cosine_similarity(pop_mean)\n",
      "    \n",
      "    # Perform cluster analysis on population variance vectors\n",
      "    kmeans = KMeans(n_clusters=2).fit(pop_variance)\n",
      "    clusters = kmeans.labels_\n",
      "    \n",
      "    # Calculate Mahalanobis distance between mean vectors\n",
      "    inv_cov_matrix = np.linalg.inv(np.cov(pop_mean.T))\n",
      "    mahal_dist = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            mahal_dist[i][j] = mahalanobis(pop_mean[i], pop_mean[j], inv_cov_matrix)\n",
      "            mahal_dist[j][i] = mahal_dist[i][j]\n",
      "    \n",
      "    # Apply kernel density estimation\n",
      "    kde = KernelDensity(bandwidth=1.0, kernel='gaussian')\n",
      "    kde.fit(pop_mean)\n",
      "    log_density = kde.score_samples(pop_mean)\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_matrix[i][j] = (cos_sim[i][j] + 1) / 2 * (1 - np.abs(clusters[i] - clusters[j])) * 1/(1 + mahal_dist[i][j]) * np.exp(log_density[i] + log_density[j])\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "Fixed RMP matrix still invalid, using default\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Better off count: 45\n",
      "Performance: 22.5\n",
      "Reverse...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\scipy\\spatial\\distance.py:1035: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(m)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating strategy\n",
      "Strategy: \n",
      "Instead of adjusting RMP values proportional to the similarity of mean vectors, adjust them inversely proportional to the similarity\n",
      "Instead of grouping tasks with similar spread together, group tasks with the most dissimilar spread together and adjust RMP values based on this dissimilarity\n",
      "Instead of adjusting RMP values inversely proportional to the Mahalanobis distance between mean vectors, adjust them directly proportional to this distance\n",
      "Instead of adjusting RMP values based on the overlap or dissimilarity of population distributions, adjust them based on the similarity or convergence of these distributions\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            mahalanobis_dist = np.linalg.norm(pop_mean[i] - pop_mean[j]) / np.sqrt(np.sum(pop_variance[i] + pop_variance[j]))\n",
      "            rmp_matrix[i][j] = mahalanobis_dist\n",
      "            rmp_matrix[j][i] = mahalanobis_dist\n",
      "    \n",
      "    rmp_matrix = 1 - rmp_matrix / np.max(rmp_matrix)\n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "Better off count: 32\n",
      "Performance: 16.0\n",
      "End LLM\n",
      "Best strategy:\n",
      " ['Calculate the Euclidean distance between the mean vectors of each pair of tasks, and adjust RMP values inversely proportional to the distance.', 'Compare the variance vectors of each pair of tasks using a statistical test such as ANOVA, and adjust RMP values based on the level of significance.', 'Cluster tasks based on the similarity of their population distributions using a clustering algorithm, and adjust RMP values based on the cluster membership of each task.', 'Calculate the correlation coefficient between the mean and variance vectors of each pair of tasks, and adjust RMP values based on the strength and direction of the correlation.']\n",
      "Best performance: 49.0\n",
      "Best RMP matrix:\n",
      " [[1.         0.70769761]\n",
      " [0.70769761 1.        ]]\n",
      "-------------------------------------------------\n",
      "Gen 200\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 1.6752579907181693, Avg: 1.6765370038985805\n",
      "Task 1, Best: 1086.857351832024, Avg: 1130.7897072748897\n",
      "Time taken each gen: 33.3559 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bfs, mfs = amfea.fit(num_gen=200,monitor=True, monitor_rate=10, llm_rate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f71a36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_tasks = len(tasks)\n",
    "# fig, axes = plt.subplots(num_tasks, 2)\n",
    "# fig.tight_layout()\n",
    "# for i in range(num_tasks):\n",
    "#     axes[i][0].plot(bfs[i])\n",
    "#     axes[i][1].plot(mfs[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
