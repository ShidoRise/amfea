{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "62bd74ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from mutation import *\n",
    "from crossover import *\n",
    "from rmp import *\n",
    "from mfea import *\n",
    "from task import *\n",
    "from llm import *\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7a396532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv()\n",
    "\n",
    "# GPT_API_KEY = os.getenv(\"GPT_API_KEY\")\n",
    "\n",
    "# llm = GPTModel(GPT_API_KEY, \"gpt-3.5-turbo-0125\", 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d98d09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cec2017_tasks = get_2_tasks(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "70978029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization:\n",
      "Task 0:\n",
      "Best Fitness: 34.629614718853325\n",
      "Mean Fitness: 43.33345570014081\n",
      "\n",
      "Task 1:\n",
      "Best Fitness: 28389.17824247567\n",
      "Mean Fitness: 41755.594589612476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_indis_per_task = 50\n",
    "indi_len = 50\n",
    "mutation = PolynomialMutation(5, 0.02)\n",
    "crossover = SBXCrossover(mutation, eta=20)\n",
    "# crossover = BLXCrossover()\n",
    "rmp = AdaptiveRMPMatrix(rmp_pop_size=4, num_gen=3, pc=0.8, pm=0.1)\n",
    "\n",
    "np.random.seed(0)\n",
    "amfea = AMFEA(num_indis_per_task, indi_len, cec2017_tasks, crossover, mutation, rmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a667e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating strategy\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the mean vectors of each task to quantify the difference in average positions. Adjust RMP values inversely proportional to the distance, so tasks with more similar mean vectors have higher RMP values.\n",
      "Compute the Mahalanobis distance between the population variance matrices of each task to capture the difference in distribution spread. Adjust RMP values based on the Mahalanobis distance, with tasks having more similar spread having higher RMP values.\n",
      "Perform a principal component analysis (PCA) on the population variance matrices of tasks to identify the dominant directions of diversity. Adjust RMP values based on the alignment of these principal components, with tasks having similar diversity directions having higher RMP values.\n",
      "Apply a clustering algorithm to group tasks based on their population statistics, then adjust RMP values within clusters to be higher than those between clusters. This ensures that tasks with similar population characteristics have higher mating probabilities.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    def mahalanobis_distance(matrix1, matrix2):\n",
      "        diff = matrix1 - matrix2\n",
      "        inv_cov = np.linalg.inv((matrix1 + matrix2) / 2)\n",
      "        return np.sqrt(np.sum(np.dot(np.dot(diff, inv_cov), diff.T)))\n",
      "\n",
      "    def pca_similarity(matrix1, matrix2):\n",
      "        u1, s1, vh1 = np.linalg.svd(matrix1)\n",
      "        u2, s2, vh2 = np.linalg.svd(matrix2)\n",
      "        return np.sum(np.abs(np.dot(u1.T, u2)))\n",
      "\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            euclidean_dist = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "            mahalanobis_dist = mahalanobis_distance(np.diag(pop_variance[i]), np.diag(pop_variance[j]))\n",
      "            pca_sim = pca_similarity(pop_variance[i], pop_variance[j])\n",
      "            rmp_matrix[i][j] = rmp_matrix[j][i] = 1 / (1 + euclidean_dist + mahalanobis_dist + pca_sim)\n",
      "\n",
      "    return rmp_matrix\n",
      "Error in creating RMP matrix: 1-dimensional array given. Array must be at least two-dimensional\n",
      "Creating strategy\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the mean vectors of each task. Adjust RMP values inversely proportional to the distance, with closer tasks having higher RMP values.\n",
      "Compute the Mahalanobis distance between the population variances of each task. Adjust RMP values inversely proportional to the distance, with tasks having similar spread having higher RMP values.\n",
      "Perform a cluster analysis on the population means of each task to identify groups of tasks with similar distributions. Adjust RMP values within each cluster to be higher and between clusters to be lower.\n",
      "Utilize a kernel density estimation on the population variances of each task to quantify the shape of the distribution. Adjust RMP values based on the overlap or separation of these distributions, with more overlap indicating higher RMP values.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.spatial.distance import mahalanobis\n",
      "from scipy.stats import gaussian_kde\n",
      "from sklearn.cluster import KMeans\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    # Euclidean distance between mean vectors\n",
      "    mean_distances = np.linalg.norm(pop_mean[:, np.newaxis] - pop_mean, axis=2)\n",
      "    mean_distances = 1 / (1 + mean_distances)\n",
      "    \n",
      "    # Mahalanobis distance between population variances\n",
      "    inv_cov_matrices = [np.diag(1 / var) for var in pop_variance]\n",
      "    mahalanobis_distances = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(task_count):\n",
      "            mahalanobis_distances[i][j] = 1 / (1 + mahalanobis(pop_mean[i], pop_mean[j], inv_cov_matrices[i] + inv_cov_matrices[j]))\n",
      "    \n",
      "    # Cluster analysis on population means\n",
      "    kmeans = KMeans(n_clusters=task_count // 2)\n",
      "    clusters = kmeans.fit_predict(pop_mean)\n",
      "    for i in range(task_count):\n",
      "        for j in range(task_count):\n",
      "            if clusters[i] == clusters[j]:\n",
      "                rmp_matrix[i][j] += 0.5\n",
      "            else:\n",
      "                rmp_matrix[i][j] -= 0.5\n",
      "    \n",
      "    # Kernel density estimation on population variances\n",
      "    kde = [gaussian_kde(var) for var in pop_variance]\n",
      "    overlap_matrix = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(task_count):\n",
      "            overlap_matrix[i][j] = kde[i].integrate_box_1d(min(pop_variance[j]), max(pop_variance[j]))\n",
      "    \n",
      "    rmp_matrix += mean_distances + mahalanobis_distances + overlap_matrix\n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    rmp_matrix = np.clip(rmp_matrix, 0, 1)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Better off count: 104\n",
      "Performance: 52.0\n",
      "Creating strategy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the mean vectors of each pair of tasks. Adjust RMP values inversely proportional to the distance: the closer the means, the higher the RMP.\n",
      "Compute the Mahalanobis distance between the mean vectors of each pair of tasks using the population variances. Adjust RMP values inversely proportional to the Mahalanobis distance.\n",
      "Assess the cosine similarity between the mean vectors of each pair of tasks. Adjust RMP values proportionally to the cosine similarity: the higher the similarity, the higher the RMP.\n",
      "Compare the variance values of each task and adjust RMP values inversely proportional to the variance: tasks with higher variance should have lower RMP values.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            euclidean_distance = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "            mahalanobis_distance = np.sqrt(np.sum(((pop_mean[i] - pop_mean[j]) ** 2) / pop_variance[i]))\n",
      "            cosine_similarity = np.dot(pop_mean[i], pop_mean[j]) / (np.linalg.norm(pop_mean[i]) * np.linalg.norm(pop_mean[j]))\n",
      "            variance_ratio = np.mean(pop_variance[i]) / np.mean(pop_variance[j])\n",
      "            \n",
      "            rmp_value = (1 + cosine_similarity) / (1 + euclidean_distance) / (1 + mahalanobis_distance) / (1 + variance_ratio)\n",
      "            \n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.        0.2815214]\n",
      " [0.2815214 1.       ]]\n",
      "Better off count: 70\n",
      "Performance: 35.0\n",
      "Creating strategy\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the mean vectors of each pair of tasks. Adjust RMP values inversely proportional to the distance, assigning higher probabilities to more similar tasks.\n",
      "Compute the cosine similarity between the mean vectors of each pair of tasks. Adjust RMP values proportionally to the similarity, assigning higher probabilities to more similar tasks.\n",
      "Analyze the variance of the population within each task. Adjust RMP values inversely proportional to the variance, assigning higher probabilities to tasks with lower variance and thus more stable distributions.\n",
      "Consider the correlation coefficient between the mean vectors of each pair of tasks. Adjust RMP values based on the strength and direction of the correlation, assigning higher probabilities to positively correlated tasks.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if i == j:\n",
      "                rmp_matrix[i][j] = 1.0\n",
      "            else:\n",
      "                euclidean_distance = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "                cosine_similarity = np.dot(pop_mean[i], pop_mean[j]) / (np.linalg.norm(pop_mean[i]) * np.linalg.norm(pop_mean[j]))\n",
      "                variance_ratio = np.sum(pop_variance[i]) / np.sum(pop_variance[j])\n",
      "                correlation_coefficient = np.corrcoef(pop_mean[i], pop_mean[j])[0][1]\n",
      "                \n",
      "                rmp_value = (1 - euclidean_distance) * cosine_similarity * (1 - variance_ratio) * (1 + correlation_coefficient)\n",
      "                rmp_matrix[i][j] = rmp_value\n",
      "                rmp_matrix[j][i] = rmp_value\n",
      "    \n",
      "    return rmp_matrix\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "Better off count: 51\n",
      "Performance: 25.5\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the cosine similarity between the mean vectors of each task. Adjust RMP values proportionally to the similarity, with more similar tasks having higher RMP values.\n",
      "Compute the Jensen-Shannon divergence between the population distributions of each task. Adjust RMP values inversely proportional to the divergence, with tasks that have more similar distributions having higher RMP values.\n",
      "Perform a Principal Component Analysis (PCA) on the population variances of each task to identify the major axes of variation. Adjust RMP values based on the alignment of these axes, with tasks that align well having higher RMP values.\n",
      "Utilize a Kolmogorov-Smirnov test on the population distributions of each task to quantify the differences in shape. Adjust RMP values based on the significance level of the test, with more significant differences indicating lower RMP values.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.spatial.distance import cosine\n",
      "from scipy.stats import entropy\n",
      "from sklearn.decomposition import PCA\n",
      "from scipy.stats import ks_2samp\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            cosine_similarity = 1 - cosine(pop_mean[i], pop_mean[j])\n",
      "            js_divergence = 0.5 * (entropy(pop_mean[i], pop_mean[j]) + entropy(pop_mean[j], pop_mean[i]))\n",
      "            \n",
      "            pca = PCA(n_components=1)\n",
      "            pca.fit(pop_variance[[i, j]])\n",
      "            pca_alignment = pca.components_[0]\n",
      "            \n",
      "            ks_stat, ks_pvalue = ks_2samp(pop_variance[i], pop_variance[j])\n",
      "            \n",
      "            rmp_value = (cosine_similarity + (1 / js_divergence) + np.abs(np.dot(pca_alignment, [1, 0])) - ks_pvalue) / 4\n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "Error in creating RMP matrix: shapes (50,) and (2,) not aligned: 50 (dim 0) != 2 (dim 0)\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the cosine dissimilarity between the mean vectors of each task. Adjust RMP values inversely proportionally to the dissimilarity, with more dissimilar tasks having higher RMP values.\n",
      "Compute the Kullback-Leibler divergence between the population distributions of each task. Adjust RMP values proportionally to the divergence, with tasks that have more dissimilar distributions having higher RMP values.\n",
      "Perform a Singular Value Decomposition (SVD) on the population variances of each task to identify the minor axes of variation. Adjust RMP values based on the misalignment of these axes, with tasks that misalign having higher RMP values.\n",
      "Utilize a Mann-Whitney U test on the population distributions of each task to quantify the similarities in shape. Adjust RMP values based on the significance level of the test, with more significant similarities indicating lower RMP values.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.spatial.distance import cosine\n",
      "from scipy.stats import entropy, mannwhitneyu\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            mean_cosine = 1 - cosine(pop_mean[i], pop_mean[j])\n",
      "            div_kl = entropy(pop_mean[i], pop_mean[j])\n",
      "            u_stat, _ = mannwhitneyu(pop_mean[i], pop_mean[j])\n",
      "            svd_result = np.linalg.svd(pop_variance[i] - pop_variance[j], compute_uv=False)\n",
      "            \n",
      "            rmp_matrix[i][j] = mean_cosine * div_kl / (1 + div_kl) * np.sum(svd_result) * (1 - u_stat / task_count)\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "Error in creating RMP matrix: 1-dimensional array given. Array must be at least two-dimensional\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the population variance matrices of each pair of tasks to capture the difference in distribution spread. Adjust RMP values inversely proportional to the distance, so tasks with more similar spread have higher mating probabilities.\n",
      "Perform a multidimensional scaling (MDS) analysis on the population mean vectors of tasks to visualize the similarity or difference in task distributions. Adjust RMP values based on the MDS results, giving higher probabilities to tasks that are closer together in the MDS space.\n",
      "Estimate the Kullback-Leibler (KL) divergence between the probability distributions of each pair of tasks to quantify the difference in information content. Adjust RMP values based on the KL divergence, assigning higher mating probabilities to tasks with lower divergence.\n",
      "Apply a spectral clustering algorithm to group tasks based on their population statistics and relationships. Adjust RMP values within clusters to be higher than those between clusters, ensuring that tasks with similar characteristics have higher mating probabilities.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.spatial.distance import pdist, squareform\n",
      "from sklearn.manifold import MDS\n",
      "from scipy.special import kl_div\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    dist = np.sqrt(np.sum((pop_variance[:, np.newaxis, :] - pop_variance) ** 2, axis=-1))\n",
      "    dist = 1 / (1 + dist)\n",
      "\n",
      "    mds = MDS(n_components=2, dissimilarity='precomputed')\n",
      "    mds_result = mds.fit_transform(dist)\n",
      "    mds_dist = pdist(mds_result)\n",
      "    mds_dist = 1 / (1 + squareform(mds_dist))\n",
      "\n",
      "    kl_divergence = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(task_count):\n",
      "            kl_divergence[i, j] = np.sum(kl_div(pop_mean[i], pop_mean[j]))\n",
      "\n",
      "    spectral_clustering = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(task_count):\n",
      "            spectral_clustering[i, j] = 1 if i == j else 0\n",
      "\n",
      "    return dist * mds_dist * kl_divergence * spectral_clustering + np.eye(task_count) * (1 - np.eye(task_count))\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "Better off count: 52\n",
      "Performance: 26.0\n",
      "End LLM\n",
      "Best strategy:\n",
      " ['Calculate the Euclidean distance between the mean vectors of each task. Adjust RMP values inversely proportional to the distance, with closer tasks having higher RMP values.', 'Compute the Mahalanobis distance between the population variances of each task. Adjust RMP values inversely proportional to the distance, with tasks having similar spread having higher RMP values.', 'Perform a cluster analysis on the population means of each task to identify groups of tasks with similar distributions. Adjust RMP values within each cluster to be higher and between clusters to be lower.', 'Utilize a kernel density estimation on the population variances of each task to quantify the shape of the distribution. Adjust RMP values based on the overlap or separation of these distributions, with more overlap indicating higher RMP values.']\n",
      "Best performance: 52.0\n",
      "Best RMP matrix:\n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "-------------------------------------------------\n",
      "Gen 0\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 33.553731670437905, Avg: 38.27132778373407\n",
      "Task 1, Best: 28230.773879799726, Avg: 36669.84314754264\n",
      "Time taken each gen: 46.2712 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 10\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 18.65547930646509, Avg: 20.521001244006342\n",
      "Task 1, Best: 18820.845343363457, Avg: 20770.056581446075\n",
      "Time taken each gen: 0.0112 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 20\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 12.32478130118894, Avg: 13.176068189013069\n",
      "Task 1, Best: 12021.280541802837, Avg: 12955.14004009907\n",
      "Time taken each gen: 0.0125 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 30\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 10.44054294924433, Avg: 11.247755080325778\n",
      "Task 1, Best: 10414.305057569603, Avg: 10841.868017763105\n",
      "Time taken each gen: 0.0116 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 40\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 9.059674750226414, Avg: 9.435620576466041\n",
      "Task 1, Best: 8448.334214314142, Avg: 8856.678297718314\n",
      "Time taken each gen: 0.0171 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 50\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 7.996824303429872, Avg: 8.27181652105801\n",
      "Task 1, Best: 7508.004881321687, Avg: 7785.0582874157335\n",
      "Time taken each gen: 0.0141 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 60\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 7.213400175286383, Avg: 7.382549209479188\n",
      "Task 1, Best: 6633.161247534565, Avg: 6921.173821793257\n",
      "Time taken each gen: 0.0110 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 70\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 6.296042803974459, Avg: 6.470622154277814\n",
      "Task 1, Best: 5630.676281074681, Avg: 5977.21587473769\n",
      "Time taken each gen: 0.0090 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 80\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 5.471020245920514, Avg: 5.636267203850482\n",
      "Task 1, Best: 4954.876427412704, Avg: 5119.106243779945\n",
      "Time taken each gen: 0.0203 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 90\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 4.54042036196475, Avg: 4.773615861001929\n",
      "Task 1, Best: 3996.7091241000708, Avg: 4201.10659978095\n",
      "Time taken each gen: 0.0100 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the cosine similarity between the population mean vectors of each pair of tasks. Adjust RMP values proportionally to the similarity, with more similar tasks having higher mating probabilities.\n",
      "Analyze the correlation matrix of the population variances for each pair of tasks. Adjust RMP values based on the strength of correlation, with highly correlated tasks having higher mating probabilities.\n",
      "Perform a principal component analysis (PCA) on the population variances of tasks to identify the main directions of variance. Adjust RMP values based on the principal components, giving higher probabilities to tasks that align with the dominant directions of variance.\n",
      "Estimate the Jensen-Shannon divergence between the probability distributions of each pair of tasks to capture the difference in information content while accounting for the overall distribution shape. Adjust RMP values based on the Jensen-Shannon divergence, assigning higher mating probabilities to tasks with lower divergence.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from scipy.stats import pearsonr\n",
      "from sklearn.decomposition import PCA\n",
      "from scipy.spatial.distance import jensenshannon\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            cos_sim = cosine_similarity([pop_mean[i]], [pop_mean[j]])[0][0]\n",
      "            pearson_corr, _ = pearsonr(pop_variance[i], pop_variance[j])\n",
      "            \n",
      "            pca = PCA(n_components=1)\n",
      "            pca.fit(np.vstack([pop_variance[i], pop_variance[j]]))\n",
      "            principal_components = pca.components_\n",
      "            \n",
      "            js_divergence = jensenshannon(pop_variance[i], pop_variance[j])\n",
      "            \n",
      "            rmp_matrix[i][j] = cos_sim * (1 + pearson_corr) * (1 + principal_components[0][0]) * (1 - js_divergence)\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return np.clip(rmp_matrix, 0, 1)\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Better off count: 92\n",
      "Performance: 46.0\n",
      "Crossover...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:653: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:653: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating strategy\n",
      "Strategy: \n",
      "Utilize a Pearson correlation analysis on the population means of each task to quantify the linear relationship between tasks. Adjust RMP values proportionally to the correlation coefficient, with highly correlated tasks having higher RMP values.\n",
      "Apply a hierarchical clustering algorithm on the population variances of each task to identify groups of tasks with similar spread. Adjust RMP values within each cluster to be higher and between clusters to be lower.\n",
      "Calculate the Jensen-Shannon divergence between the probability distributions of each pair of tasks based on the kernel density estimation of population variances. Adjust RMP values inversely proportional to the divergence, with more divergent tasks having lower RMP values.\n",
      "Perform a principal component analysis on the population means and variances to identify the major sources of variance between tasks. Adjust RMP values based on the principal components, giving higher weight to components that explain more variance.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.stats import pearsonr\n",
      "from scipy.spatial.distance import pdist, squareform\n",
      "from sklearn.cluster import AgglomerativeClustering\n",
      "from sklearn.metrics import pairwise_distances\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.neighbors import KernelDensity\n",
      "from sklearn.metrics import jensenshannon\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    # Pearson correlation analysis\n",
      "    cor_matrix = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            cor_matrix[i][j] = cor_matrix[j][i] = pearsonr(pop_mean[i], pop_mean[j])[0]\n",
      "\n",
      "    # Hierarchical clustering\n",
      "    scaler = StandardScaler()\n",
      "    scaled_pop_variance = scaler.fit_transform(pop_variance)\n",
      "    clustering = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward').fit(scaled_pop_variance)\n",
      "    cluster_labels = clustering.labels_\n",
      "\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if cluster_labels[i] == cluster_labels[j]:\n",
      "                rmp_matrix[i][j] = rmp_matrix[j][i] = max(cor_matrix[i][j], 0)\n",
      "            else:\n",
      "                rmp_matrix[i][j] = rmp_matrix[j][i] = max(cor_matrix[i][j], 0) * 0.5\n",
      "\n",
      "    # Jensen-Shannon divergence\n",
      "    kde = KernelDensity(bandwidth=1.0, kernel='gaussian')\n",
      "    kde.fit(pop_variance)\n",
      "    prob_dist = np.exp(kde.score_samples(pop_variance))\n",
      "    js_matrix = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            js_matrix[i][j] = js_matrix[j][i] = jensenshannon(prob_dist[i], prob_dist[j])\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            rmp_matrix[i][j] = rmp_matrix[j][i] = rmp_matrix[i][j] * (1 - js_matrix[i][j])\n",
      "\n",
      "    # Principal component analysis\n",
      "    pca = PCA(n_components=2)\n",
      "    pca.fit(np.concatenate((pop_mean, pop_variance), axis=1))\n",
      "    components = pca.components_\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            rmp_matrix[i][j] = rmp_matrix[j][i] = rmp_matrix[i][j] * (1 + np.dot(components[:, i], components[:, j]))\n",
      "\n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "\n",
      "    return rmp_matrix\n",
      "Error in creating RMP matrix: cannot import name 'jensenshannon' from 'sklearn.metrics' (d:\\ANACONDA\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Utilize a Spearman rank correlation analysis on the population means of each task to quantify the non-linear relationships between tasks. Adjust RMP values inversely proportional to the correlation coefficient, with highly correlated tasks having lower RMP values.\n",
      "Apply a k-means clustering algorithm on the population variances of each task to identify distinct clusters of tasks with different spread. Adjust RMP values within each cluster to be lower and between clusters to be higher.\n",
      "Calculate the Kullback-Leibler divergence between the probability distributions of each pair of tasks based on the histogram of population variances. Adjust RMP values directly proportional to the divergence, with more similar tasks having lower RMP values.\n",
      "Perform a feature selection analysis on the population means and variances to identify the minor sources of variance between tasks. Adjust RMP values based on the minor components, giving lower weight to components that explain less variance.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.stats import spearmanr\n",
      "from sklearn.cluster import KMeans\n",
      "from scipy.stats import entropy\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    \n",
      "    # Spearman rank correlation analysis\n",
      "    spearman_corr = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            corr, _ = spearmanr(pop_mean[i], pop_mean[j])\n",
      "            spearman_corr[i][j] = corr\n",
      "            spearman_corr[j][i] = corr\n",
      "    \n",
      "    RMP -= spearman_corr\n",
      "    \n",
      "    # K-means clustering\n",
      "    kmeans = KMeans(n_clusters=2).fit(pop_variance)\n",
      "    labels = kmeans.labels_\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if labels[i] == labels[j]:\n",
      "                RMP[i][j] *= 0.5\n",
      "                RMP[j][i] *= 0.5\n",
      "            else:\n",
      "                RMP[i][j] *= 2.0\n",
      "                RMP[j][i] *= 2.0\n",
      "    \n",
      "    # Kullback-Leibler divergence\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            kl_div = entropy(pop_variance[i], pop_variance[j])\n",
      "            RMP[i][j] += kl_div\n",
      "            RMP[j][i] += kl_div\n",
      "    \n",
      "    # Feature selection analysis\n",
      "    mean_components = np.mean(pop_mean, axis=0)\n",
      "    var_components = np.mean(pop_variance, axis=0)\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            RMP[i][j] *= mean_components[j] + var_components[j]\n",
      "            RMP[j][i] *= mean_components[i] + var_components[i]\n",
      "    \n",
      "    np.fill_diagonal(RMP, 1.0)\n",
      "    \n",
      "    return RMP\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "Better off count: 49\n",
      "Performance: 24.5\n",
      "Crossover...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the population mean vectors of each pair of tasks. Adjust RMP values inversely proportional to the distance, with closer tasks having higher mating probabilities.\n",
      "Analyze the covariance matrix of the population variances for each pair of tasks. Adjust RMP values based on the strength of covariance, with tasks having higher covariance having higher mating probabilities.\n",
      "Perform a cluster analysis on the population variances of tasks to identify groups of tasks with similar variance patterns. Adjust RMP values based on the cluster assignments, giving higher probabilities to tasks within the same cluster.\n",
      "Estimate the Kullback-Leibler divergence between the probability distributions of each pair of tasks to measure the difference in information content while penalizing deviations from the overall distribution shape. Adjust RMP values based on the Kullback-Leibler divergence, assigning higher mating probabilities to tasks with lower divergence.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            euclidean_distance = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "            covariance_strength = np.cov(pop_variance[i], pop_variance[j])[0, 1]\n",
      "            rmp_matrix[i][j] = rmp_matrix[j][i] = 1 / (1 + euclidean_distance) * (1 + covariance_strength)\n",
      "    \n",
      "    return rmp_matrix\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1.         0.87851034]\n",
      " [0.87851034 1.        ]]\n",
      "Better off count: 83\n",
      "Performance: 41.5\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Focus on increasing the mating probabilities between tasks with the highest Euclidean distance in population mean vectors, promoting diversity and exploration across disparate areas of the search space.\n",
      "Prioritize RMP adjustments based on the independence of population variances for each pair of tasks, with tasks showing the least covariance having higher mating probabilities to encourage exploration of diverse directions.\n",
      "Disregard cluster analysis results and assign equal RMP values to all task pairs, regardless of variance patterns, to prevent bias towards specific groups of tasks.\n",
      "Emphasize mating probabilities between tasks with the highest Kullback-Leibler divergence, favoring pairs with significant differences in distribution shape to promote exploration of unique regions in the search space.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            euclidean_distance = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "            kl_divergence = np.sum(np.log(pop_variance[j] / pop_variance[i]) + (pop_variance[i] / pop_variance[j]) - 1)\n",
      "            \n",
      "            rmp_matrix[i][j] = np.exp(-euclidean_distance) * np.exp(-kl_divergence)\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "Better off count: 48\n",
      "Performance: 24.0\n",
      "End LLM\n",
      "Best strategy:\n",
      " ['Calculate the Euclidean distance between the mean vectors of each task. Adjust RMP values inversely proportional to the distance, with closer tasks having higher RMP values.', 'Compute the Mahalanobis distance between the population variances of each task. Adjust RMP values inversely proportional to the distance, with tasks having similar spread having higher RMP values.', 'Perform a cluster analysis on the population means of each task to identify groups of tasks with similar distributions. Adjust RMP values within each cluster to be higher and between clusters to be lower.', 'Utilize a kernel density estimation on the population variances of each task to quantify the shape of the distribution. Adjust RMP values based on the overlap or separation of these distributions, with more overlap indicating higher RMP values.']\n",
      "Best performance: 52.0\n",
      "Best RMP matrix:\n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "-------------------------------------------------\n",
      "Gen 100\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 3.826256218315591, Avg: 4.066929420011617\n",
      "Task 1, Best: 3324.3136898798334, Avg: 3586.453209224911\n",
      "Time taken each gen: 31.0604 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 110\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 3.4782018753631077, Avg: 3.651248443671056\n",
      "Task 1, Best: 2954.443181957157, Avg: 3110.312390819878\n",
      "Time taken each gen: 0.0222 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 120\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 3.060310124654169, Avg: 3.1198411371340704\n",
      "Task 1, Best: 2544.597827099757, Avg: 2587.986720639072\n",
      "Time taken each gen: 0.0191 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 130\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.828863069468281, Avg: 2.8834983900387465\n",
      "Task 1, Best: 2320.7864998983023, Avg: 2340.637360280414\n",
      "Time taken each gen: 0.0160 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 140\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.4052208615539517, Avg: 2.582244165669611\n",
      "Task 1, Best: 1884.9305137459621, Avg: 2034.7222762638019\n",
      "Time taken each gen: 0.0185 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 150\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.162397741227276, Avg: 2.2590158996800516\n",
      "Task 1, Best: 1666.8189132119949, Avg: 1744.2148390518769\n",
      "Time taken each gen: 0.0267 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 160\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.0409865587630893, Avg: 2.072213856792857\n",
      "Task 1, Best: 1468.8627324742865, Avg: 1549.4384184672238\n",
      "Time taken each gen: 0.0204 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 170\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 1.9226470122781425, Avg: 1.9928686970636236\n",
      "Task 1, Best: 1428.124720405759, Avg: 1454.3907357350458\n",
      "Time taken each gen: 0.0181 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 180\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 1.7943906248813772, Avg: 1.8552458357863935\n",
      "Task 1, Best: 1262.2738786038076, Avg: 1310.6258528099781\n",
      "Time taken each gen: 0.0276 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Gen 190\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 1.6614262136386095, Avg: 1.7061274819332033\n",
      "Task 1, Best: 1040.4498848768592, Avg: 1129.382851310556\n",
      "Time taken each gen: 0.0381 seconds\n",
      "\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating RMP matrix: 'AdaptiveRMPMatrix' object has no attribute 'validate_rmp_matrix'\n",
      "RMP_Matrix:\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the population mean vectors of each pair of tasks. Adjust RMP values inversely proportional to the distance, with closer tasks having higher mating probabilities.\n",
      "Analyze the covariance matrix of the population variances for each pair of tasks. Adjust RMP values based on the strength of covariance, with tasks that exhibit similar variance patterns having higher mating probabilities.\n",
      "Perform a multidimensional scaling (MDS) on the population variances of tasks to visualize the pairwise distances in a lower-dimensional space. Adjust RMP values based on the MDS distances, giving higher probabilities to tasks that cluster together.\n",
      "Estimate the Bhattacharyya distance between the probability distributions of each pair of tasks to capture the overlap in their distributions. Adjust RMP values based on the Bhattacharyya distance, assigning higher mating probabilities to tasks with lower overlap.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "from scipy.spatial.distance import pdist, squareform\n",
      "from sklearn.metrics import pairwise_distances\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    euclidean_distances = pairwise_distances(pop_mean, metric='euclidean')\n",
      "    covariance_matrix = np.corrcoef(pop_variance)\n",
      "    mds_distances = pairwise_distances(pop_variance, metric='euclidean')\n",
      "    bhattacharyya_distances = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            bhattacharyya_distance = np.sum(np.sqrt(pop_variance[i] * pop_variance[j]))\n",
      "            bhattacharyya_distances[i][j] = bhattacharyya_distance\n",
      "            bhattacharyya_distances[j][i] = bhattacharyya_distance\n",
      "    \n",
      "    rmp_matrix = 1 / (euclidean_distances + 1) * covariance_matrix * (1 / (mds_distances + 1)) * (1 / (bhattacharyya_distances + 1))\n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "Better off count: 42\n",
      "Performance: 21.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Instead of adjusting RMP values based on the Euclidean distance between population mean vectors, prioritize tasks with the most similar mean vectors by assigning lower mating probabilities to them.\n",
      "Rather than adjusting RMP values based on covariance strength in population variances, prioritize tasks with the most distinct variance patterns by assigning higher mating probabilities to them.\n",
      "Instead of adjusting RMP values based on MDS distances of tasks, prioritize tasks that are more scattered or dissimilar in the lower-dimensional space by assigning higher mating probabilities to them.\n",
      "Instead of adjusting RMP values based on Bhattacharyya distance between probability distributions, prioritize tasks with more overlapping distributions by assigning higher mating probabilities to them.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if i == j:\n",
      "                rmp_matrix[i][j] = 1.0\n",
      "            else:\n",
      "                mean_diff = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "                var_diff = np.linalg.norm(pop_variance[i] - pop_variance[j])\n",
      "                \n",
      "                rmp_matrix[i][j] = 1 - (mean_diff + var_diff) / 2\n",
      "                rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.        0.9339553]\n",
      " [0.9339553 1.       ]]\n",
      "Better off count: 70\n",
      "Performance: 35.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the population mean vectors of each pair of tasks. Adjust RMP values inversely proportional to the distance, with closer tasks having higher mating probabilities.\n",
      "Analyze the covariance matrix of the population variances for each pair of tasks. Adjust RMP values based on the strength of covariance, with tasks that exhibit similar variance patterns having higher mating probabilities.\n",
      "Perform a multidimensional scaling (MDS) analysis on the population mean vectors to visualize the dissimilarities between tasks in a lower-dimensional space. Adjust RMP values based on the MDS distances, with tasks that cluster together indicating higher mating probabilities.\n",
      "Estimate the Kullback-Leibler divergence between the probability distributions of each pair of tasks to quantify the information gain by switching between tasks. Adjust RMP values based on the Kullback-Leibler divergence, assigning higher mating probabilities to tasks with lower divergence.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            euclidean_dist = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "            covariance_strength = np.cov(pop_variance[i], pop_variance[j])[0, 1]\n",
      "            mds_dist = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "            kl_divergence = np.sum(pop_mean[i] * np.log(pop_mean[i]/pop_mean[j]))\n",
      "            \n",
      "            rmp_value = 1 / (1 + euclidean_dist) + 1 / (1 + abs(covariance_strength)) + 1 / (1 + mds_dist) + 1 / (1 + kl_divergence)\n",
      "            \n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Better off count: 52\n",
      "Performance: 26.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Instead of adjusting RMP values based on the Euclidean distance between population mean vectors, prioritize task pairs with greater distance to have higher mating probabilities.\n",
      "Analyze the covariance matrix of population variances for each pair of tasks, but adjust RMP values inversely proportional to the strength of covariance. Tasks with dissimilar variance patterns should have higher mating probabilities.\n",
      "Instead of adjusting RMP values based on MDS distances that indicate task dissimilarities, prioritize tasks that cluster together in the lower-dimensional space to have lower mating probabilities.\n",
      "Estimate the Kullback-Leibler divergence between probability distributions of task pairs, but adjust RMP values based on the inverse of the divergence. Tasks with higher divergence should have higher mating probabilities.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    RMP = np.ones((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            dist = np.linalg.norm(pop_mean[i] - pop_mean[j])\n",
      "            cov_strength = np.cov(pop_variance[i], pop_variance[j])[0, 1]\n",
      "            kl_divergence = np.sum(pop_variance[i] * np.log(pop_variance[i] / pop_variance[j]))\n",
      "            RMP[i][j] = 1 / (1 + dist) * (1 / (1 + cov_strength)) * (1 / (1 + kl_divergence))\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    return RMP\n",
      "[[1.         0.82688557]\n",
      " [0.82688557 1.        ]]\n",
      "Better off count: 58\n",
      "Performance: 28.999999999999996\n",
      "Mutation...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Consider the skewness of the population distribution for each task and adjust RMP values inversely proportional to the absolute difference in skewness between task pairs. Tasks with more skewed distributions should have higher mating probabilities.\n",
      "Analyze the kurtosis of the population distribution for each task and adjust RMP values based on the difference in kurtosis between task pairs. Tasks with higher kurtosis values should have lower mating probabilities to encourage exploration in flatter regions of the search space.\n",
      "Introduce a measure of entropy for each task's population distribution and adjust RMP values based on the difference in entropy between task pairs. Tasks with higher entropy, indicating more diversity, should have lower mating probabilities to promote adaptation in less explored regions.\n",
      "Calculate the Mahalanobis distance between population mean vectors of task pairs, considering the covariance matrix of the entire population. Adjust RMP values based on the Mahalanobis distance to prioritize mating between tasks with more orthogonal distributions and reduce mating probabilities for tasks with highly correlated population distributions.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            skew_diff = abs(np.mean(pop_mean[i]) - np.mean(pop_mean[j]))\n",
      "            kurt_diff = abs(np.mean(pop_variance[i]) - np.mean(pop_variance[j]))\n",
      "            entropy_diff = abs(np.sum(pop_mean[i] * np.log(pop_mean[i])) - np.sum(pop_mean[j] * np.log(pop_mean[j])))\n",
      "            \n",
      "            mahalanobis_distance = np.linalg.norm(pop_mean[i] - pop_mean[j]) / np.sqrt(np.sum(pop_variance, axis=0))\n",
      "            \n",
      "            rmp_value = 1 / (1 + skew_diff) / (1 + kurt_diff) / (1 + entropy_diff) / (1 + mahalanobis_distance)\n",
      "            \n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "Error in creating RMP matrix: setting an array element with a sequence.\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Calculate the Euclidean distance between the population mean vectors of each pair of tasks. Adjust RMP values inversely proportional to the distance, with closer tasks having higher mating probabilities.\n",
      "Analyze the covariance matrix of the population variances for each pair of tasks. Adjust RMP values based on the strength of covariance, with tasks that exhibit similar variance patterns having higher mating probabilities.\n",
      "Perform a multidimensional scaling (MDS) on the population variances of tasks to visualize the similarity in variance structures. Adjust RMP values based on the MDS results, giving higher probabilities to tasks that cluster together in the MDS plot.\n",
      "Estimate the Kullback-Leibler divergence between the probability distributions of each pair of tasks to measure the difference in information content. Adjust RMP values based on the KL divergence, assigning higher mating probabilities to tasks with lower divergence.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    def euclidean_distance(x, y):\n",
      "        return np.linalg.norm(x - y)\n",
      "    \n",
      "    def adjust_rmp_value(dist):\n",
      "        return 1 / (1 + dist)\n",
      "    \n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            dist = euclidean_distance(pop_mean[i], pop_mean[j])\n",
      "            rmp_matrix[i][j] = rmp_matrix[j][i] = adjust_rmp_value(dist)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.         0.88560013]\n",
      " [0.88560013 1.        ]]\n",
      "Better off count: 70\n",
      "Performance: 35.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy: \n",
      "Focus on maximizing the mating probabilities between tasks with the highest Euclidean distance in population mean vectors, promoting diversity in offspring generation.\n",
      "Analyze the covariance matrix of the population variances for each pair of tasks to identify tasks with dissimilar variance patterns. Adjust RMP values to favor mating between tasks with distinct variance structures.\n",
      "Perform MDS on the population variances of tasks to identify tasks that are spread out or unique in their variance distributions. Adjust RMP values to prioritize mating between tasks that are not clustered together in the MDS plot.\n",
      "Estimate the Kullback-Leibler divergence between the probability distributions of each pair of tasks to measure the uniqueness or information richness of tasks. Adjust RMP values to favor mating between tasks with higher KL divergence, promoting exploration and information exchange.\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, pop_mean, pop_variance):\n",
      "    def euclidean_distance(v1, v2):\n",
      "        return np.linalg.norm(v1 - v2)\n",
      "\n",
      "    def kl_divergence(p, q):\n",
      "        return np.sum(p * np.log(p / q))\n",
      "\n",
      "    rmp = np.zeros((task_count, task_count))\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if i == j:\n",
      "                rmp[i][j] = 1.0\n",
      "            else:\n",
      "                dist = euclidean_distance(pop_mean[i], pop_mean[j])\n",
      "                variance_cov = np.cov(pop_variance[i], pop_variance[j])[0][1]\n",
      "                mds_similarity = np.exp(-np.abs(np.mean(pop_variance[i]) - np.mean(pop_variance[j])))\n",
      "                kl_div = kl_divergence(pop_variance[i], pop_variance[j])\n",
      "                rmp[i][j] = rmp[j][i] = (dist + variance_cov + mds_similarity + kl_div) / 4\n",
      "\n",
      "    return rmp\n",
      "[[1.         0.30001033]\n",
      " [0.30001033 1.        ]]\n",
      "Better off count: 60\n",
      "Performance: 30.0\n",
      "End LLM\n",
      "Best strategy:\n",
      " ['Calculate the Euclidean distance between the mean vectors of each task. Adjust RMP values inversely proportional to the distance, with closer tasks having higher RMP values.', 'Compute the Mahalanobis distance between the population variances of each task. Adjust RMP values inversely proportional to the distance, with tasks having similar spread having higher RMP values.', 'Perform a cluster analysis on the population means of each task to identify groups of tasks with similar distributions. Adjust RMP values within each cluster to be higher and between clusters to be lower.', 'Utilize a kernel density estimation on the population variances of each task to quantify the shape of the distribution. Adjust RMP values based on the overlap or separation of these distributions, with more overlap indicating higher RMP values.']\n",
      "Best performance: 52.0\n",
      "Best RMP matrix:\n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "-------------------------------------------------\n",
      "Gen 200\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 1.5759325546051843, Avg: 1.617777050344415\n",
      "Task 1, Best: 1014.8368035369272, Avg: 1037.1495740007422\n",
      "Time taken each gen: 31.5398 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bfs, mfs = amfea.fit(num_gen=200,monitor=True, monitor_rate=10, llm_rate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f71a36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_tasks = len(tasks)\n",
    "# fig, axes = plt.subplots(num_tasks, 2)\n",
    "# fig.tight_layout()\n",
    "# for i in range(num_tasks):\n",
    "#     axes[i][0].plot(bfs[i])\n",
    "#     axes[i][1].plot(mfs[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
