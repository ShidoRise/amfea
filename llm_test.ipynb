{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62bd74ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from mutation import *\n",
    "from crossover import *\n",
    "from rmp import *\n",
    "from mfea import *\n",
    "from task import *\n",
    "from llm import *\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a396532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv()\n",
    "\n",
    "# GPT_API_KEY = os.getenv(\"GPT_API_KEY\")\n",
    "\n",
    "# llm = GPTModel(GPT_API_KEY, \"gpt-3.5-turbo-0125\", 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d98d09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cec2017_tasks = get_2_tasks(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70978029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization:\n",
      "Task 0:\n",
      "Best Fitness: 32.57331352041355\n",
      "Mean Fitness: 42.48531687978877\n",
      "\n",
      "Task 1:\n",
      "Best Fitness: 33448.860280631605\n",
      "Mean Fitness: 43021.8221136689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_indis_per_task = 50\n",
    "indi_len = 50\n",
    "mutation = PolynomialMutation(5, 0.02)\n",
    "crossover = SBXCrossover(mutation, eta=2)\n",
    "# crossover = BLXCrossover()\n",
    "rmp = AdaptiveRMPMatrix(rmp_pop_size=4, num_gen=3, pc=0.8, pm=0.1)\n",
    "\n",
    "amfea = AMFEA(num_indis_per_task, indi_len, cec2017_tasks, crossover, mutation, rmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a667e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 0\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 23.550269596315047, Avg: 34.35587516815545\n",
      "Task 1, Best: 21413.124583760058, Avg: 33542.731645091946\n",
      "Time taken each gen: 0.0035 seconds\n",
      "\n",
      "Creating strategy\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign higher RMP values to tasks with higher genetic diversity\n",
      "Assign higher RMP values to tasks with lower convergence rates\n",
      "Assign higher RMP values to tasks with higher fitness variance\n",
      "Adjust RMP values based on offspring success rate to promote better fitness improvement\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_matrix[i][j] = (diversity[i] + fitness_variance[i] - convergence[i]) * offspring_success_rate\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    return rmp_matrix\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "Better off count: 66\n",
      "Performance: 33.0\n",
      "Creating strategy\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Increase RMP for tasks with higher genetic diversity values\n",
      "Adjust RMP based on convergence rates to promote exploration or exploitation\n",
      "Set RMP higher for tasks with lower fitness variance values to maintain diversity\n",
      "Determine RMP based on offspring success rate to balance exploitation and exploration\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.ones((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_value = (diversity[i] + diversity[j]) / 2\n",
      "            rmp_value *= (1 - convergence[i]) * (1 - convergence[j])\n",
      "            rmp_value *= 1 - (fitness_variance[i] + fitness_variance[j]) / 2\n",
      "            rmp_value *= (1 + offspring_success_rate) / 2\n",
      "            \n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "    \n",
      "    return rmp_matrix\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "Better off count: 75\n",
      "Performance: 37.5\n",
      "Creating strategy\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Set RMP values based on the genetic diversity of each task, giving higher probabilities to tasks with lower diversity to promote exploration\n",
      "Adjust RMP values based on the convergence rates of tasks, assigning higher probabilities to tasks that are converging slower to prevent premature convergence\n",
      "Incorporate fitness variance values into the RMP matrix calculation, assigning higher probabilities to tasks with higher fitness variance to encourage exploration of different solutions\n",
      "Utilize the offspring success rate to dynamically adjust RMP values, increasing probabilities for tasks with higher success rates to exploit successful solutions\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.ones((task_count, task_count))\n",
      "    \n",
      "    diversity = np.array(diversity)\n",
      "    convergence = np.array(convergence)\n",
      "    fitness_variance = np.array(fitness_variance)\n",
      "    \n",
      "    rmp_matrix = 1 - diversity[:, np.newaxis] * diversity / np.sum(diversity)\n",
      "    \n",
      "    rmp_matrix = rmp_matrix + (1 - convergence[:, np.newaxis] * convergence) / np.sum(1 - convergence)\n",
      "    \n",
      "    rmp_matrix = rmp_matrix + fitness_variance[:, np.newaxis] * fitness_variance / np.sum(fitness_variance)\n",
      "    \n",
      "    rmp_matrix = rmp_matrix * offspring_success_rate\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.         0.60265365]\n",
      " [0.60265365 1.        ]]\n",
      "Better off count: 76\n",
      "Performance: 38.0\n",
      "Creating strategy\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Calculate the average fitness variance across all tasks and set RMP values inversely proportional to the fitness variance values\n",
      "Assign higher RMP values to tasks with higher diversity values to encourage mating among diverse individuals\n",
      "Adjust RMP values based on the offspring success rate, assigning higher probabilities to tasks with higher success rates\n",
      "Utilize a weighted combination of convergence rates and diversity values to determine RMP values for each task\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    avg_fitness_variance = np.mean(fitness_variance)\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            rmp_ij = 1 / (1 + avg_fitness_variance * fitness_variance[i] * fitness_variance[j])\n",
      "            rmp_ij *= (1 + diversity[i]) * (1 + diversity[j])\n",
      "            rmp_ij *= (1 + offspring_success_rate)\n",
      "            rmp_ij *= (1 + convergence[i] + diversity[i]) / (1 + convergence[j] + diversity[j])\n",
      "            rmp_matrix[i][j] = rmp_ij\n",
      "            rmp_matrix[j][i] = rmp_ij\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.0000000e+00 1.4482229e-08]\n",
      " [1.4482229e-08 1.0000000e+00]]\n",
      "Better off count: 74\n",
      "Performance: 37.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of genetic diversity and fitness variance, giving higher probabilities to tasks with both low diversity and high fitness variance\n",
      "Incorporate convergence rates into the RMP matrix calculation by adjusting RMP values inversely proportional to the convergence rates of tasks\n",
      "Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate, increasing probabilities for tasks with higher success rates\n",
      "Regularly update RMP values during the optimization process based on the individual task's performance and adaptability to promote a balance between exploration and exploitation\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            rmp_ij = (1 - diversity[i]) + fitness_variance[j]\n",
      "            rmp_ij /= (1 + convergence[i])\n",
      "            rmp_ij *= (1 + offspring_success_rate)\n",
      "            rmp_ij = max(0, min(1, rmp_ij))\n",
      "            rmp_matrix[i][j] = rmp_ij\n",
      "            rmp_matrix[j][i] = rmp_ij\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Better off count: 80\n",
      "Performance: 40.0\n",
      "['Assign RMP values based on a weighted combination of genetic diversity and fitness variance, giving higher probabilities to tasks with both low diversity and high fitness variance', 'Incorporate convergence rates into the RMP matrix calculation by adjusting RMP values inversely proportional to the convergence rates of tasks', 'Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate, increasing probabilities for tasks with higher success rates', \"Regularly update RMP values during the optimization process based on the individual task's performance and adaptability to promote a balance between exploration and exploitation\"]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates, giving higher probabilities to tasks with low diversity, high fitness variance, and low convergence rates\n",
      "Incorporate offspring success rate into the RMP matrix calculation by adjusting RMP values proportionally to the success rates of tasks\n",
      "Implement a mechanism to dynamically adjust RMP values based on both individual task's performance and adaptability, balancing between exploration and exploitation\n",
      "Regularly update RMP values during the optimization process based on the feedback from the offspring success rate and task performance to ensure optimal exploration and exploitation\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_value = (1 - diversity[i]) + fitness_variance[j] - convergence[i]\n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "    \n",
      "    rmp_matrix = rmp_matrix / np.max(rmp_matrix)\n",
      "    \n",
      "    rmp_matrix = rmp_matrix * offspring_success_rate\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        rmp_matrix[i][i] = 1.0\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.   0.27]\n",
      " [0.27 1.  ]]\n",
      "Better off count: 51\n",
      "Performance: 25.5\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates, giving higher probabilities to tasks with high diversity, low fitness variance, and high convergence rates\n",
      "Incorporate offspring success rate into the RMP matrix calculation by adjusting RMP values inversely proportional to the success rates of tasks\n",
      "Implement a mechanism to keep RMP values static based on individual task's performance and adaptability, favoring either pure exploration or exploitation without balance\n",
      "Irregularly update RMP values during the optimization process based on random feedback from the offspring success rate and task performance to ensure suboptimal exploration and exploitation\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            rmp_value = (diversity[i] + convergence[j]) / (1 + fitness_variance[i]) * (1 - offspring_success_rate)\n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.00000000e+00 1.80365038e-04]\n",
      " [1.80365038e-04 1.00000000e+00]]\n",
      "Better off count: 64\n",
      "Performance: 32.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Adjust RMP based on both genetic diversity and convergence rates to balance exploration and exploitation\n",
      "Set RMP higher for tasks with lower fitness variance values to maintain diversity\n",
      "Determine RMP based on offspring success rate and genetic diversity values to optimize exploitation\n",
      "Consider task_count in determining RMP values to ensure scalability and efficiency\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.ones((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_matrix[i][j] = 1 / (1 + np.exp(diversity[i] + diversity[j]))\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "            \n",
      "            rmp_matrix[i][j] *= (1 - convergence[i]) * (1 - convergence[j])\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "            \n",
      "            if fitness_variance[i] < fitness_variance[j]:\n",
      "                rmp_matrix[i][j] *= 1.2\n",
      "                rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "                \n",
      "            if offspring_success_rate > 0.5:\n",
      "                rmp_matrix[i][j] += 0.1\n",
      "                rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.         0.59992382]\n",
      " [0.59992382 1.        ]]\n",
      "Better off count: 55\n",
      "Performance: 27.500000000000004\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Set RMP higher for tasks with higher fitness variance values to promote convergence\n",
      "Adjust RMP based on genetic diversity and convergence rates to favor exploitation over exploration\n",
      "Base RMP on offspring success rate and convergence rates to maximize diversity\n",
      "Ignore task_count when determining RMP values to prioritize specific task performance\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            rmp_matrix[i][j] = 1.0 - (fitness_variance[i] + fitness_variance[j]) / 2\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "            \n",
      "            rmp_matrix[i][j] *= (1 + (diversity[i] + diversity[j]) / 2) * (1 + (convergence[i] + convergence[j]) / 2)\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "            \n",
      "            rmp_matrix[i][j] *= (1 + offspring_success_rate) * (1 + (convergence[i] + convergence[j]) / 2)\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "            \n",
      "            rmp_matrix[i][j] = max(0, min(1, rmp_matrix[i][j]))\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Better off count: 51\n",
      "Performance: 25.5\n",
      "['Assign RMP values based on a weighted combination of genetic diversity and fitness variance, giving higher probabilities to tasks with both low diversity and high fitness variance', 'Incorporate convergence rates into the RMP matrix calculation by adjusting RMP values inversely proportional to the convergence rates of tasks', 'Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate, increasing probabilities for tasks with higher success rates', \"Regularly update RMP values during the optimization process based on the individual task's performance and adaptability to promote a balance between exploration and exploitation\"]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Gen 100\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.9572192393373236, Avg: 2.957221593416965\n",
      "Task 1, Best: 2334.8665050484105, Avg: 2334.8665171657335\n",
      "Time taken each gen: 21.6136 seconds\n",
      "\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Calculate RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates\n",
      "Adjust RMP values dynamically during the optimization process based on the offspring success rate\n",
      "Regularly update RMP values based on individual task performance and adaptability to maintain a balance between exploration and exploitation\n",
      "Set RMP higher for tasks with lower fitness variance values to promote diversity and exploration\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_matrix[i][j] = (0.4 * diversity[i] + 0.3 * fitness_variance[i] + 0.3 * convergence[i]) * offspring_success_rate\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        rmp_matrix[i][i] = 1.0\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.00000000e+00 2.10958005e-07]\n",
      " [2.10958005e-07 1.00000000e+00]]\n",
      "Better off count: 52\n",
      "Performance: 26.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Set RMP higher for tasks with higher fitness variance values to promote exploitation over exploration\n",
      "Regularly update RMP values based on individual task performance and adaptability to maintain a balance between exploitation and exploration\n",
      "Adjust RMP values dynamically during the optimization process based on the offspring success rate, prioritizing tasks with lower success rates\n",
      "Calculate RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates, favoring tasks with lower diversity and convergence rates\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if i == j:\n",
      "                RMP[i][j] = 1.0\n",
      "            else:\n",
      "                weight = (fitness_variance[i] + fitness_variance[j]) / 2\n",
      "                RMP[i][j] = weight * (1 - offspring_success_rate) + (1 - weight) * (1 - diversity[i]) * (1 - convergence[i])\n",
      "                RMP[j][i] = RMP[i][j]\n",
      "    return RMP\n",
      "[[1.        0.9999976]\n",
      " [0.9999976 1.       ]]\n",
      "Better off count: 36\n",
      "Performance: 18.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Adjust RMP values based on genetic diversity and convergence rates to balance exploration and exploitation\n",
      "Incorporate fitness variance values into RMP matrix calculation to encourage exploration of different solutions\n",
      "Utilize offspring success rate to dynamically adjust RMP values for exploiting successful solutions\n",
      "Set RMP values based on a weighted combination of diversity, convergence, fitness variance, and offspring success rate to optimize crossover process\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.ones((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            RMP[i][j] = (diversity[i] + convergence[i] + fitness_variance[i] + offspring_success_rate) / 4\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    \n",
      "    return RMP\n",
      "[[1.        0.0550006]\n",
      " [0.0550006 1.       ]]\n",
      "Better off count: 43\n",
      "Performance: 21.5\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Adjust RMP values based on fitness variance and offspring success rate to prioritize exploitation over exploration\n",
      "Incorporate genetic diversity values into RMP matrix calculation to discourage exploration of different solutions\n",
      "Utilize convergence rates to statically adjust RMP values for avoiding successful solutions\n",
      "Set RMP values based on a weighted combination of offspring success rate, convergence, genetic diversity, and fitness variance to optimize mutation process\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.ones((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            RMP[i][j] = (diversity[i] + diversity[j]) * (1 - convergence[i] - convergence[j]) * (1 - fitness_variance[i] - fitness_variance[j]) * offspring_success_rate\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    \n",
      "    return RMP\n",
      "[[1.00000000e+00 5.27474795e-07]\n",
      " [5.27474795e-07 1.00000000e+00]]\n",
      "Better off count: 42\n",
      "Performance: 21.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Calculate a weighted average of genetic diversity, convergence rate, fitness variance, and offspring success rate to determine RMP values\n",
      "Adjust RMP values dynamically based on individual task performance and adaptability\n",
      "Regularly update RMP values during the optimization process to maintain a balance between exploration and exploitation\n",
      "Incorporate feedback mechanisms to continuously optimize RMP values for each task\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    weights = np.array([0.3, 0.2, 0.2, 0.3])\n",
      "    values = np.array([diversity, convergence, fitness_variance, offspring_success_rate])\n",
      "    weighted_values = np.average(values, weights=weights, axis=0)\n",
      "    \n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            RMP[i][j] = RMP[j][i] = min(1.0, weighted_values[i] * weighted_values[j])\n",
      "    \n",
      "    return RMP\n",
      "Error in creating RMP matrix: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "[[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "Better off count: 46\n",
      "Performance: 23.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Set RMP values randomly without considering task performance or adaptability\n",
      "Maintain static RMP values throughout the optimization process\n",
      "Avoid updating RMP values to limit exploration and focus on exploitation\n",
      "Exclude feedback mechanisms and rely solely on preset RMP values\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    np.random.seed(42)\n",
      "    rmp_matrix = np.random.rand(task_count, task_count)\n",
      "    rmp_matrix = (rmp_matrix + rmp_matrix.T) / 2\n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.         0.84135412]\n",
      " [0.84135412 1.        ]]\n",
      "Better off count: 37\n",
      "Performance: 18.5\n",
      "['Assign RMP values based on a weighted combination of genetic diversity and fitness variance, giving higher probabilities to tasks with both low diversity and high fitness variance', 'Incorporate convergence rates into the RMP matrix calculation by adjusting RMP values inversely proportional to the convergence rates of tasks', 'Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate, increasing probabilities for tasks with higher success rates', \"Regularly update RMP values during the optimization process based on the individual task's performance and adaptability to promote a balance between exploration and exploitation\"]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Gen 200\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.957192648907771, Avg: 2.957192648950088\n",
      "Task 1, Best: 2334.865552395778, Avg: 2334.865552395847\n",
      "Time taken each gen: 18.0326 seconds\n",
      "\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates\n",
      "Implement a dynamic adjustment mechanism for RMP values based on the offspring success rate and adaptability\n",
      "Regularly update RMP values during the optimization process based on individual task's performance and success rate\n",
      "Include a penalty mechanism for tasks with consistently low success rates to encourage exploration and prevent premature convergence\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            if i == j:\n",
      "                RMP[i][j] = 1.0\n",
      "            else:\n",
      "                weighted_sum = (0.4 * diversity[i] + 0.3 * fitness_variance[i] + 0.3 * convergence[i]) + (0.1 * diversity[j] + 0.2 * fitness_variance[j] + 0.2 * convergence[j])\n",
      "                RMP[i][j] = weighted_sum / 2\n",
      "                RMP[j][i] = RMP[i][j]\n",
      "    \n",
      "    RMP *= offspring_success_rate\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        success_rate = np.mean(RMP[i])\n",
      "        if success_rate < 0.2:\n",
      "            RMP[i] *= 0.5\n",
      "    \n",
      "    return RMP\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1.00000000e+00 2.66296284e-10]\n",
      " [2.66296284e-10 1.00000000e+00]]\n",
      "Better off count: 35\n",
      "Performance: 17.5\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a random distribution without considering genetic diversity, fitness variance, and convergence rates\n",
      "Implement a static adjustment mechanism for RMP values that does not consider offspring success rate and adaptability\n",
      "Infrequently update RMP values during the optimization process regardless of individual task's performance and success rate\n",
      "Exclude penalty mechanism for tasks with consistently low success rates to avoid discouraging exploration and encourage premature convergence\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.random.rand(task_count, task_count)\n",
      "    rmp_matrix = (rmp_matrix + rmp_matrix.T) / 2\n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    return rmp_matrix\n",
      "[[1.         0.14512893]\n",
      " [0.14512893 1.        ]]\n",
      "Better off count: 41\n",
      "Performance: 20.5\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Adjust RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates\n",
      "Incorporate task success rates into the RMP matrix calculation by adjusting RMP values proportionally to the success rates\n",
      "Regularly update RMP values during the optimization process based on the individual task's performance, adaptability, and success rates\n",
      "Maintain a balance between exploration and exploitation by dynamically adjusting RMP values based on the task's genetic diversity, convergence rates, and fitness variance\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.identity(task_count)\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_ij = (diversity[i] + fitness_variance[i] + convergence[i]) / 3\n",
      "            rmp_ji = (diversity[j] + fitness_variance[j] + convergence[j]) / 3\n",
      "            rmp_matrix[i][j] = rmp_ij * offspring_success_rate\n",
      "            rmp_matrix[j][i] = rmp_ji * offspring_success_rate\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.00000000e+00 8.66174468e-10]\n",
      " [8.59248309e-11 1.00000000e+00]]\n",
      "Better off count: 48\n",
      "Performance: 24.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Maintain a balance between exploitation and exploration by keeping RMP values static based on the task's genetic diversity, convergence rates, and fitness variance\n",
      "Regularly update RMP values during the optimization process based on the overall performance of all tasks, disregarding individual task success rates\n",
      "Incorporate task failure rates into the RMP matrix calculation by adjusting RMP values inversely proportional to the failure rates\n",
      "Adjust RMP values based solely on genetic diversity, convergence rates, and fitness variance without considering a weighted combination of these factors\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.ones((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_value = (diversity[i] + diversity[j]) / 2 * (convergence[i] + convergence[j]) / 2 * (fitness_variance[i] + fitness_variance[j]) / 2\n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.00000000e+00 1.39673136e-45]\n",
      " [1.39673136e-45 1.00000000e+00]]\n",
      "Better off count: 44\n",
      "Performance: 22.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Set RMP values based on a weighted combination of genetic diversity, convergence rates, fitness variance, and offspring success rate for each task\n",
      "Adjust RMP values dynamically based on the evolution progress of each task, giving higher probabilities to tasks that are lagging behind to promote balanced exploration and exploitation\n",
      "Incorporate a mechanism to adaptively update RMP values based on the historical performance of tasks, prioritizing tasks with inconsistent performance to encourage further exploration\n",
      "Regularly monitor and analyze the distribution of offsprings' fitness improvements to fine-tune RMP values and ensure a consistent improvement in overall performance\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.ones((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            RMP[i][j] = (diversity[i] + convergence[i] + fitness_variance[i] + offspring_success_rate) / 4\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "\n",
      "    return RMP\n",
      "[[1.      0.05125]\n",
      " [0.05125 1.     ]]\n",
      "Better off count: 44\n",
      "Performance: 22.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Set RMP values based on a weighted combination of genetic diversity, convergence rates, fitness variance, and offspring success rate for each task\n",
      "Adjust RMP values statically based on the evolution progress of each task, giving higher probabilities to tasks that are excelling to promote specialized exploration and exploitation\n",
      "Incorporate a mechanism to adaptively update RMP values based on the historical performance of tasks, prioritizing tasks with consistent performance to discourage further exploration\n",
      "Regularly monitor and analyze the distribution of offsprings' fitness improvements to maintain static RMP values and ensure a consistent performance level\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_value = (diversity[i] + convergence[i] + fitness_variance[i] + offspring_success_rate) / 4.0\n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        rmp_matrix[i][i] = 1.0\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.      0.05125]\n",
      " [0.05125 1.     ]]\n",
      "Better off count: 53\n",
      "Performance: 26.5\n",
      "['Assign RMP values based on a weighted combination of genetic diversity and fitness variance, giving higher probabilities to tasks with both low diversity and high fitness variance', 'Incorporate convergence rates into the RMP matrix calculation by adjusting RMP values inversely proportional to the convergence rates of tasks', 'Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate, increasing probabilities for tasks with higher success rates', \"Regularly update RMP values during the optimization process based on the individual task's performance and adaptability to promote a balance between exploration and exploitation\"]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Gen 300\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.957192648807467, Avg: 2.957192648807511\n",
      "Task 1, Best: 2334.865552395415, Avg: 2334.8655523954226\n",
      "Time taken each gen: 20.9719 seconds\n",
      "\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Adjust RMP based on both genetic diversity and convergence rates to balance exploration and exploitation\n",
      "Set RMP higher for tasks with lower fitness variance values to maintain diversity\n",
      "Increase RMP for tasks with higher offspring success rates to promote exploration\n",
      "Consider task count when determining RMP to ensure a balanced approach across all tasks\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.ones((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            RMP[i][j] = RMP[j][i] = (1 - diversity[i]) * convergence[j] + (1 - convergence[i]) * diversity[j]\n",
      "            RMP[i][j] = RMP[j][i] = RMP[i][j] * (1 - fitness_variance[i]) + RMP[i][j] * fitness_variance[j]\n",
      "            RMP[i][j] = RMP[j][i] = RMP[i][j] * (1 + offspring_success_rate)\n",
      "    \n",
      "    return RMP\n",
      "[[1.00000000e+00 1.31166219e-10]\n",
      " [1.31166219e-10 1.00000000e+00]]\n",
      "Better off count: 41\n",
      "Performance: 20.5\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Set RMP higher for tasks with higher fitness variance values to encourage convergence\n",
      "Decrease RMP for tasks with higher offspring success rates to limit exploration\n",
      "Ignore task count when determining RMP to focus on specific tasks\n",
      "Adjust RMP based on genetic diversity only to prioritize exploitation over exploration\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.ones((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_value = (1 - fitness_variance[i]) + (1 - fitness_variance[j]) + (1 - offspring_success_rate)\n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "    return rmp_matrix\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Better off count: 30\n",
      "Performance: 15.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates\n",
      "Regularly update RMP values during the optimization process based on the individual task's performance and adaptability\n",
      "Incorporate offspring success rate into the RMP matrix calculation to balance exploitation and exploration\n",
      "Adjust RMP values based on the overall success rate of crossover offsprings to promote a balance between exploration and exploitation\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            RMP[i][j] = RMP[j][i] = (diversity[i] + fitness_variance[i] + convergence[i]) / 3.0 * offspring_success_rate\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        RMP[i][i] = 1.0\n",
      "    \n",
      "    return RMP\n",
      "[[1.00000000e+00 9.02994674e-11]\n",
      " [9.02994674e-11 1.00000000e+00]]\n",
      "Better off count: 42\n",
      "Performance: 21.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates\n",
      "Regularly update RMP values during the optimization process based on the individual task's performance and adaptability\n",
      "Incorporate offspring success rate into the RMP matrix calculation to balance exploitation and exploration\n",
      "Adjust RMP values based on the overall success rate of crossover offsprings to promote a balance between exploration and exploitation\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            RMP[i][j] = (diversity[i] + fitness_variance[i] + convergence[i]) / 3 * offspring_success_rate\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    np.fill_diagonal(RMP, 1.0)\n",
      "    return RMP\n",
      "[[1.00000000e+00 9.02994674e-11]\n",
      " [9.02994674e-11 1.00000000e+00]]\n",
      "Better off count: 37\n",
      "Performance: 18.5\n",
      "['Assign RMP values based on a weighted combination of genetic diversity and fitness variance, giving higher probabilities to tasks with both low diversity and high fitness variance', 'Incorporate convergence rates into the RMP matrix calculation by adjusting RMP values inversely proportional to the convergence rates of tasks', 'Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate, increasing probabilities for tasks with higher success rates', \"Regularly update RMP values during the optimization process based on the individual task's performance and adaptability to promote a balance between exploration and exploitation\"]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Gen 400\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.957192648807399, Avg: 2.9571926488073994\n",
      "Task 1, Best: 2334.865552395032, Avg: 2334.865552395037\n",
      "Time taken each gen: 16.6678 seconds\n",
      "\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates, giving higher probabilities to tasks with low diversity, high fitness variance, and low convergence rates\n",
      "Incorporate offspring success rate into the RMP matrix calculation by adjusting RMP values proportionally to the success rates of tasks\n",
      "Implement a dynamic adjustment mechanism for RMP values based on the individual task's performance and adaptability, increasing probabilities for tasks with higher success rates and lower convergence rates\n",
      "Regularly update RMP values during the optimization process based on the tasks' genetic diversity, fitness variance, convergence rates, and offspring success rate to promote a balance between exploration and exploitation\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            rmp_value = (1 - diversity[i]) + fitness_variance[j] - convergence[i]\n",
      "            rmp_value *= (1 + offspring_success_rate)\n",
      "            RMP[i][j] = RMP[j][i] = max(0, min(1, rmp_value))\n",
      "    \n",
      "    np.fill_diagonal(RMP, 1.0)\n",
      "    \n",
      "    return RMP\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Better off count: 35\n",
      "Performance: 17.5\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of high genetic diversity, low fitness variance, and high convergence rates, giving lower probabilities to tasks with low diversity, high fitness variance, and low convergence rates\n",
      "Incorporate offspring success rate into the RMP matrix calculation by adjusting RMP values inversely proportional to the success rates of tasks\n",
      "Implement a static adjustment mechanism for RMP values based on the individual task's performance and adaptability, decreasing probabilities for tasks with higher success rates and lower convergence rates\n",
      "Irregularly update RMP values during the optimization process based on the tasks' genetic diversity, fitness variance, convergence rates, and offspring success rate to promote imbalance between exploration and exploitation\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.ones((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            RMP[i][j] = (1 - offspring_success_rate) * (1 - (diversity[i] + diversity[j]) / 2) + (1 - fitness_variance[i] - fitness_variance[j]) / 2 + (convergence[i] + convergence[j]) / 2\n",
      "    \n",
      "    RMP = np.triu(RMP) + np.triu(RMP, 1).T\n",
      "    \n",
      "    return RMP\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Better off count: 29\n",
      "Performance: 14.499999999999998\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates\n",
      "Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate and individual task's performance\n",
      "Regularly update RMP values during the optimization process based on the adaptability of tasks to promote a balance between exploration and exploitation\n",
      "Consider the task_count to dynamically adjust RMP values to ensure a fair distribution of probabilities among tasks\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            RMP[i][j] = (diversity[i] + fitness_variance[j]) / (convergence[i] + 1)\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    \n",
      "    RMP = RMP / np.max(RMP)\n",
      "    \n",
      "    return RMP + offspring_success_rate * np.eye(task_count) - np.mean(RMP)\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1.  0.5]\n",
      " [0.5 1. ]]\n",
      "Better off count: 38\n",
      "Performance: 19.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a random distribution without considering genetic diversity, fitness variance, and convergence rates\n",
      "Utilize a static adjustment mechanism for RMP values that does not consider offspring success rate or individual task's performance\n",
      "Infrequently update RMP values during the optimization process regardless of the adaptability of tasks\n",
      "Ignore the task_count and assign equal RMP values to all tasks\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.random.rand(task_count, task_count)\n",
      "    rmp_matrix = (rmp_matrix + rmp_matrix.T) / 2\n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.         0.55814496]\n",
      " [0.55814496 1.        ]]\n",
      "Better off count: 38\n",
      "Performance: 19.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a combination of genetic diversity, fitness variance, and convergence rates, giving higher probabilities to tasks with low diversity, high fitness variance, and low convergence rates\n",
      "Incorporate a penalty mechanism for tasks with low offspring success rates, decreasing their RMP values to promote exploration\n",
      "Implement a dynamic adjustment mechanism for RMP values based on the task's historical performance trends, adjusting probabilities accordingly\n",
      "Regularly update RMP values during the optimization process based on the task's real-time performance metrics and adaptability to strike a balance between exploration and exploitation\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.ones((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            penalty = 0\n",
      "            if offspring_success_rate < 0.5:\n",
      "                penalty = 0.5 - offspring_success_rate\n",
      "            RMP[i][j] = (1 - diversity[i]) * fitness_variance[j] * (1 - convergence[j]) - penalty\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    \n",
      "    return RMP\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "Better off count: 29\n",
      "Performance: 14.499999999999998\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a combination of high genetic diversity, low fitness variance, and high convergence rates, giving higher probabilities to tasks with these characteristics\n",
      "Incorporate a reward mechanism for tasks with high offspring success rates, increasing their RMP values to promote exploitation\n",
      "Implement a static adjustment mechanism for RMP values based on the task's historical performance trends, maintaining probabilities regardless of task performance\n",
      "Infrequently update RMP values during the optimization process based on the task's real-time performance metrics and adaptability to maintain a consistent balance between exploration and exploitation\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.ones((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_matrix[i][j] = (diversity[i] + convergence[i] - fitness_variance[i]) * offspring_success_rate\n",
      "            rmp_matrix[j][i] = rmp_matrix[i][j]\n",
      "    return np.clip(rmp_matrix, 0, 1)\n",
      "[[1.00000000e+00 1.29980339e-10]\n",
      " [1.29980339e-10 1.00000000e+00]]\n",
      "Better off count: 37\n",
      "Performance: 18.5\n",
      "['Assign RMP values based on a weighted combination of genetic diversity and fitness variance, giving higher probabilities to tasks with both low diversity and high fitness variance', 'Incorporate convergence rates into the RMP matrix calculation by adjusting RMP values inversely proportional to the convergence rates of tasks', 'Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate, increasing probabilities for tasks with higher success rates', \"Regularly update RMP values during the optimization process based on the individual task's performance and adaptability to promote a balance between exploration and exploitation\"]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Gen 500\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.957192648807366, Avg: 2.957192648807368\n",
      "Task 1, Best: 2334.865552394857, Avg: 2334.8655523948623\n",
      "Time taken each gen: 22.7625 seconds\n",
      "\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Adjust RMP values based on the genetic diversity of each task, assigning higher probabilities to tasks with lower diversity to promote exploration\n",
      "Incorporate convergence rates into the RMP matrix calculation, assigning higher probabilities to tasks that are converging slower to prevent premature convergence\n",
      "Utilize fitness variance values to dynamically adjust RMP values, assigning higher probabilities to tasks with higher fitness variance to encourage exploration of different solutions\n",
      "Integrate offspring success rate into the RMP matrix calculation, increasing probabilities for tasks with higher success rates to exploit successful solutions\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.ones((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            RMP[i][j] = (diversity[j] * (1 - convergence[j]) * fitness_variance[j] * offspring_success_rate) / (diversity[i] * (1 - convergence[i]) * fitness_variance[i] * offspring_success_rate)\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "            RMP[i][j] = max(0, min(1, RMP[i][j]))\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    \n",
      "    return RMP\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Better off count: 29\n",
      "Performance: 14.499999999999998\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Adjust RMP values based on the genetic diversity of each task, assigning higher probabilities to tasks with higher diversity to promote exploitation\n",
      "Incorporate convergence rates into the RMP matrix calculation, assigning higher probabilities to tasks that are converging faster to encourage premature convergence\n",
      "Utilize fitness variance values to dynamically adjust RMP values, assigning higher probabilities to tasks with lower fitness variance to discourage exploration of different solutions\n",
      "Integrate offspring success rate into the RMP matrix calculation, decreasing probabilities for tasks with higher success rates to explore unsuccessful solutions\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.ones((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            RMP[i][j] = diversity[i] * (1 - convergence[j]) * (1 - fitness_variance[j]) * (1 - offspring_success_rate)\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    \n",
      "    return RMP\n",
      "[[1.00000000e+00 3.24602856e-09]\n",
      " [3.24602856e-09 1.00000000e+00]]\n",
      "Better off count: 33\n",
      "Performance: 16.5\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Adjust RMP based on a weighted combination of genetic diversity, convergence rates, and fitness variance values for each task\n",
      "Set RMP higher for tasks with higher weighted values to promote exploration and maintain diversity\n",
      "Determine RMP based on a combination of offspring success rate and the weighted values to balance exploitation and exploration effectively\n",
      "Regularly update RMP based on the performance feedback of offsprings to continuously adapt to the evolving task landscape\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    weighted_values = np.array(diversity) + np.array(convergence) + np.array(fitness_variance)\n",
      "    normalized_values = weighted_values / np.sum(weighted_values)\n",
      "    rmp_matrix = np.outer(normalized_values, normalized_values)\n",
      "    rmp_matrix = rmp_matrix * offspring_success_rate + (1 - offspring_success_rate) * np.identity(task_count)\n",
      "    \n",
      "    return rmp_matrix\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1.         0.01955223]\n",
      " [0.01955223 1.        ]]\n",
      "Better off count: 33\n",
      "Performance: 16.5\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Set RMP lower for tasks with higher weighted values to promote exploitation and focus on fine-tuning\n",
      "Determine RMP based solely on offspring success rate, disregarding genetic diversity and convergence rates\n",
      "Infrequently update RMP based on the performance feedback of offsprings to maintain stability and consistency\n",
      "Focus on maintaining a fixed RMP value for each task regardless of evolving task landscape\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.ones((task_count, task_count))\n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    rmp_value = 1.0 - offspring_success_rate\n",
      "    rmp_matrix = np.full((task_count, task_count), rmp_value)\n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.   0.84]\n",
      " [0.84 1.  ]]\n",
      "Better off count: 34\n",
      "Performance: 17.0\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates, giving higher probabilities to tasks with lower diversity, higher fitness variance, and slower convergence rates\n",
      "Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate, increasing probabilities for tasks with higher success rates\n",
      "Regularly update RMP values during the optimization process based on the individual task's performance, adaptability, and historical success rates to promote a balance between exploration and exploitation\n",
      "Incorporate a feedback mechanism that adjusts RMP values based on the overall population diversity and fitness improvement trends to further enhance exploration and exploitation capabilities\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            weight = 0.4 * (1 - diversity[i]) + 0.3 * fitness_variance[j] + 0.3 * (1 - convergence[j])\n",
      "            RMP[i][j] = weight\n",
      "            \n",
      "    RMP = np.maximum(RMP, RMP.T)\n",
      "    RMP += offspring_success_rate\n",
      "    \n",
      "    return np.clip(RMP, 0, 1)\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1.   0.86]\n",
      " [0.86 1.  ]]\n",
      "Better off count: 32\n",
      "Performance: 16.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates, giving higher probabilities to tasks with higher diversity, lower fitness variance, and faster convergence rates\n",
      "Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate, decreasing probabilities for tasks with higher success rates\n",
      "Regularly update RMP values during the optimization process based on the individual task's performance, adaptability, and historical failure rates to promote a balance between exploitation and exploration\n",
      "Incorporate a feedback mechanism that adjusts RMP values based on the overall population homogeneity and fitness deterioration trends to further enhance exploitation and exploration capabilities\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            rmp_value = (1 - (diversity[i] + diversity[j]) / 2) * (1 - (convergence[i] + convergence[j]) / 2) * (1 - (fitness_variance[i] + fitness_variance[j]) / 2)\n",
      "            rmp_value *= (1 - offspring_success_rate)\n",
      "            \n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.   0.84]\n",
      " [0.84 1.  ]]\n",
      "Better off count: 26\n",
      "Performance: 13.0\n",
      "['Assign RMP values based on a weighted combination of genetic diversity and fitness variance, giving higher probabilities to tasks with both low diversity and high fitness variance', 'Incorporate convergence rates into the RMP matrix calculation by adjusting RMP values inversely proportional to the convergence rates of tasks', 'Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate, increasing probabilities for tasks with higher success rates', \"Regularly update RMP values during the optimization process based on the individual task's performance and adaptability to promote a balance between exploration and exploitation\"]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Gen 600\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.957192648807321, Avg: 2.957192648807322\n",
      "Task 1, Best: 2334.8655523946654, Avg: 2334.86555239467\n",
      "Time taken each gen: 23.4550 seconds\n",
      "\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Set RMP values based on the genetic diversity of each task, giving higher probabilities to tasks with lower diversity to promote exploration\n",
      "Adjust RMP values based on the convergence rates of tasks, assigning higher probabilities to tasks that are converging slower to prevent premature convergence\n",
      "Incorporate fitness variance values into the RMP matrix calculation, assigning higher probabilities to tasks with higher fitness variance to encourage exploration of different solutions\n",
      "Utilize the offspring success rate to dynamically adjust RMP values, increasing probabilities for tasks with higher success rates to exploit successful solutions\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.ones((task_count, task_count))\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            rmp_value = (1 - diversity[i]) * (1 - convergence[i]) * fitness_variance[i] * offspring_success_rate\n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "\n",
      "    return rmp_matrix\n",
      "[[1.00000000e+00 1.27795466e-32]\n",
      " [1.27795466e-32 1.00000000e+00]]\n",
      "Better off count: 26\n",
      "Performance: 13.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Set RMP values based on the genetic diversity of each task, giving higher probabilities to tasks with higher diversity to promote exploitation\n",
      "Adjust RMP values based on the convergence rates of tasks, assigning higher probabilities to tasks that are converging faster to encourage premature convergence\n",
      "Incorporate fitness variance values into the RMP matrix calculation, assigning higher probabilities to tasks with lower fitness variance to discourage exploration of different solutions\n",
      "Utilize the offspring success rate to dynamically adjust RMP values, decreasing probabilities for tasks with higher success rates to avoid exploiting successful solutions\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            RMP[i][j] = diversity[i] / (diversity[i] + diversity[j])\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "            \n",
      "            RMP[i][j] *= (1 - convergence[i]) / (1 + convergence[i])\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "            \n",
      "            RMP[i][j] *= 1 / (1 + fitness_variance[i])\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "            \n",
      "            RMP[i][j] *= 1 - (offspring_success_rate / 2)\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    \n",
      "    np.fill_diagonal(RMP, 1.0)\n",
      "    \n",
      "    return RMP\n",
      "[[1.         0.83942818]\n",
      " [0.83942818 1.        ]]\n",
      "Better off count: 15\n",
      "Performance: 7.5\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Adjust RMP values based on a weighted combination of genetic diversity, convergence rates, and fitness variance, giving higher probabilities to tasks with both low diversity and high fitness variance\n",
      "Incorporate a dynamic adjustment mechanism for RMP values based on the offspring success rate, increasing probabilities for tasks with higher success rates\n",
      "Regularly update RMP values during the optimization process based on the individual task's performance and adaptability to promote a balance between exploration and exploitation\n",
      "Set RMP higher for tasks with lower fitness variance values to maintain diversity and balance exploitation and exploration\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            RMP[i][j] = RMP[j][i] = (1 - diversity[i]) * (1 - fitness_variance[i]) + (1 - convergence[i])\n",
      "    \n",
      "    RMP += offspring_success_rate * np.eye(task_count)\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        RMP[i] = np.where(fitness_variance < fitness_variance[i], RMP[i] + 0.1, RMP[i])\n",
      "    \n",
      "    return np.clip(RMP, 0, 1)\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Better off count: 22\n",
      "Performance: 11.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Adjust RMP values based on a weighted combination of genetic diversity, convergence rates, and fitness variance, giving higher probabilities to tasks with both high diversity and low fitness variance\n",
      "Incorporate a dynamic adjustment mechanism for RMP values based on the offspring success rate, decreasing probabilities for tasks with higher success rates\n",
      "Regularly update RMP values during the optimization process based on the individual task's performance and adaptability to promote a bias towards either exploration or exploitation\n",
      "Set RMP higher for tasks with higher fitness variance values to reduce diversity and focus on exploitation over exploration\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.ones((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i + 1, task_count):\n",
      "            RMP[i][j] = (1 - offspring_success_rate) * (diversity[i] + 1 - fitness_variance[i]) * (1 - convergence[j]) / (task_count - 1)\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    return RMP\n",
      "[[1.         0.86500001]\n",
      " [0.86500001 1.        ]]\n",
      "Better off count: 31\n",
      "Performance: 15.5\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates, with higher probabilities given to tasks with low diversity, high fitness variance, and slow convergence rates\n",
      "Incorporate a reinforcement learning mechanism to adjust RMP values based on the success rate of offsprings, rewarding tasks with higher success rates\n",
      "Implement a self-adaptive mechanism to dynamically adjust RMP values based on the performance and adaptability of individual tasks, promoting a balance between exploration and exploitation\n",
      "Regularly update RMP values during the optimization process based on the overall progress and efficiency of the algorithm to ensure continuous improvement\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            RMP[i][j] = (1 - diversity[i]) + fitness_variance[j] + (1 - convergence[i])\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "\n",
      "    RMP = RMP / np.max(RMP)\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            RMP[i][j] = RMP[i][j] * offspring_success_rate\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "\n",
      "    return RMP\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1.    0.135]\n",
      " [0.135 1.   ]]\n",
      "Better off count: 26\n",
      "Performance: 13.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of high genetic diversity, low fitness variance, and fast convergence rates, with higher probabilities given to tasks with these characteristics\n",
      "Incorporate a reinforcement learning mechanism to adjust RMP values based on the failure rate of offsprings, penalizing tasks with lower success rates\n",
      "Implement a self-adaptive mechanism to statically adjust RMP values based on the performance and adaptability of individual tasks, promoting a lack of balance between exploration and exploitation\n",
      "Irregularly update RMP values during the optimization process based on the overall lack of progress and inefficiency of the algorithm to ensure continuous stagnation\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.identity(task_count)\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i+1, task_count):\n",
      "            weight = (0.4 * diversity[i] + 0.3 * (1 - fitness_variance[i]) + 0.3 * (1 - convergence[i])) / 3\n",
      "            weight += (1 - offspring_success_rate)\n",
      "            rmp_matrix[i][j] = weight\n",
      "            rmp_matrix[j][i] = weight\n",
      "    \n",
      "    return rmp_matrix\n",
      "Invalid RMP matrix generated, attempting to fix\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Better off count: 28\n",
      "Performance: 14.000000000000002\n",
      "['Assign RMP values based on a weighted combination of genetic diversity and fitness variance, giving higher probabilities to tasks with both low diversity and high fitness variance', 'Incorporate convergence rates into the RMP matrix calculation by adjusting RMP values inversely proportional to the convergence rates of tasks', 'Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate, increasing probabilities for tasks with higher success rates', \"Regularly update RMP values during the optimization process based on the individual task's performance and adaptability to promote a balance between exploration and exploitation\"]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Gen 700\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.9571926487617013, Avg: 2.9571926487617013\n",
      "Task 1, Best: 2334.865552394488, Avg: 2334.865552394493\n",
      "Time taken each gen: 24.0143 seconds\n",
      "\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Calculate RMP values based on a weighted combination of genetic diversity, convergence rates, and fitness variance, giving higher probabilities to tasks with lower diversity, slower convergence rates, and higher fitness variance\n",
      "Incorporate the offspring success rate into the RMP matrix calculation by dynamically adjusting RMP values, increasing probabilities for tasks with higher success rates\n",
      "Regularly update RMP values during the optimization process based on the individual task's performance, adaptability, and the overall success rate of offsprings to maintain a balance between exploration and exploitation\n",
      "Implement a feedback mechanism to adjust RMP values based on the effectiveness of the current strategy, promoting the exploration of promising solutions and exploiting successful solutions\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            RMP[i][j] = (1 - diversity[i]) + (1 - convergence[i]) + fitness_variance[i]\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    \n",
      "    RMP = RMP / np.max(RMP)\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(task_count):\n",
      "            RMP[i][j] = RMP[i][j] + (offspring_success_rate * (1 - RMP[i][j]))\n",
      "    \n",
      "    return RMP\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Better off count: 33\n",
      "Performance: 16.5\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Calculate RMP values based on a weighted combination of genetic diversity, convergence rates, and fitness variance, giving higher probabilities to tasks with higher diversity, faster convergence rates, and lower fitness variance\n",
      "Incorporate the offspring success rate into the RMP matrix calculation by reducing probabilities for tasks with higher success rates\n",
      "Irregularly update RMP values during the optimization process based on the individual task's performance, adaptability, and the overall success rate of offsprings to maintain an imbalance between exploration and exploitation\n",
      "Implement a feedback mechanism to adjust RMP values based on the ineffectiveness of the current strategy, promoting the exploitation of unpromising solutions and exploring unsuccessful solutions\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            RMP[i][j] = (diversity[i] + convergence[i] + fitness_variance[i]) / 3\n",
      "            RMP[i][j] *= (1 - offspring_success_rate)\n",
      "            RMP[j][i] = RMP[i][j]\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        RMP[i][i] = 1.0\n",
      "    \n",
      "    return RMP\n",
      "[[1.00000000e+00 2.82896485e-10]\n",
      " [2.82896485e-10 1.00000000e+00]]\n",
      "Better off count: 35\n",
      "Performance: 17.5\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Calculate RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates\n",
      "Adjust RMP values based on offspring success rates to promote a balance between exploration and exploitation\n",
      "Regularly update RMP values during the optimization process based on individual task performance and adaptability\n",
      "Implement a dynamic adjustment mechanism for RMP values based on the overall success rate of crossover offsprings\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    RMP = np.zeros((task_count, task_count))\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            value = (diversity[i] + convergence[i] + fitness_variance[i]) / 3\n",
      "            RMP[i][j] = value\n",
      "            RMP[j][i] = value\n",
      "    RMP = RMP * offspring_success_rate\n",
      "    np.fill_diagonal(RMP, 1.0)\n",
      "    return RMP\n",
      "[[1.00000000e+00 5.79426535e-11]\n",
      " [5.79426535e-11 1.00000000e+00]]\n",
      "Better off count: 34\n",
      "Performance: 17.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Calculate RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates\n",
      "Adjust RMP values based on offspring success rates to hinder a balance between exploration and exploitation\n",
      "Regularly update RMP values during the optimization process based on individual task underperformance and rigidity\n",
      "Implement a static adjustment mechanism for RMP values based on the overall failure rate of crossover offsprings\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "\n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            rmp_value = (diversity[i] + fitness_variance[i] + convergence[i]) / 3.0\n",
      "            rmp_value *= (diversity[j] + fitness_variance[j] + convergence[j]) / 3.0\n",
      "            rmp_value *= offspring_success_rate\n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "\n",
      "    for i in range(task_count):\n",
      "        rmp_matrix[i][i] = 1.0\n",
      "\n",
      "    return rmp_matrix\n",
      "[[1.00000000e+00 7.40824017e-21]\n",
      " [7.40824017e-21 1.00000000e+00]]\n",
      "Better off count: 40\n",
      "Performance: 20.0\n",
      "['Assign RMP values based on a weighted combination of genetic diversity and fitness variance, giving higher probabilities to tasks with both low diversity and high fitness variance', 'Incorporate convergence rates into the RMP matrix calculation by adjusting RMP values inversely proportional to the convergence rates of tasks', 'Utilize a dynamic adjustment mechanism for RMP values based on the offspring success rate, increasing probabilities for tasks with higher success rates', \"Regularly update RMP values during the optimization process based on the individual task's performance and adaptability to promote a balance between exploration and exploitation\"]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Gen 800\n",
      "Evaluation count: 0\n",
      "Task 0, Best: 2.9571926487616365, Avg: 2.9571926487616382\n",
      "Task 1, Best: 2334.8655523943303, Avg: 2334.8655523943394\n",
      "Time taken each gen: 18.5831 seconds\n",
      "\n",
      "Crossover...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of genetic diversity, fitness variance, and convergence rates\n",
      "Regularly update RMP values during the optimization process based on the individual task's performance, adaptability, and success rate\n",
      "Incorporate a dynamic adjustment mechanism for RMP values based on the balance between exploration and exploitation\n",
      "Set RMP higher for tasks with both low diversity and high fitness variance values to promote diversity and improve overall performance\n",
      "Creating code...\n",
      "RMP function: import numpy as np\n",
      "\n",
      "def get_rmp_matrix(task_count, diversity, convergence, fitness_variance, offspring_success_rate):\n",
      "    rmp_matrix = np.zeros((task_count, task_count))\n",
      "    \n",
      "    for i in range(task_count):\n",
      "        for j in range(i, task_count):\n",
      "            rmp_value = (diversity[i] + fitness_variance[i] + convergence[i]) * (diversity[j] + fitness_variance[j] + convergence[j]) * offspring_success_rate\n",
      "            rmp_matrix[i][j] = rmp_value\n",
      "            rmp_matrix[j][i] = rmp_value\n",
      "    \n",
      "    np.fill_diagonal(rmp_matrix, 1.0)\n",
      "    \n",
      "    return rmp_matrix\n",
      "[[1.00000000e+00 6.17702637e-20]\n",
      " [6.17702637e-20 1.00000000e+00]]\n",
      "Better off count: 46\n",
      "Performance: 23.0\n",
      "Reverse...\n",
      "Evaluating strategy\n",
      "Strategy:\n",
      " Assign RMP values based on a weighted combination of task success rate, fitness variance, and convergence rates\n",
      "Regularly update RMP values during the optimization process based on the collective task performance, adaptability, and success rate\n",
      "Incorporate a static adjustment mechanism for RMP values based on the balance between exploration and exploitation\n",
      "Set RMP higher for tasks with both high diversity and low fitness variance values to encourage uniformity and stabilize overall performance\n",
      "Creating code...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bfs, mfs \u001b[38;5;241m=\u001b[39m amfea\u001b[38;5;241m.\u001b[39mfit(num_gen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, llm_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32md:\\PYTHON\\NCKH\\amfea\\mfea\\amfea.py:193\u001b[0m, in \u001b[0;36mAMFEA.fit\u001b[1;34m(self, max_eval, num_gen, monitor, monitor_rate, llm_rate)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_gen \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    192\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevolve(gen, llm_rate, lookback\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    194\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminate:\n",
      "File \u001b[1;32md:\\PYTHON\\NCKH\\amfea\\mfea\\amfea.py:158\u001b[0m, in \u001b[0;36mAMFEA.evolve\u001b[1;34m(self, gen, llm_rate, lookback)\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gen \u001b[38;5;241m%\u001b[39m llm_rate \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m gen \u001b[38;5;241m==\u001b[39m lookback \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    157\u001b[0m         collect_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect_population_state(gen, lookback, success_rate)\n\u001b[1;32m--> 158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marmp_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrmp(collect_state, p1, p2, p1_skill_factor, p2_skill_factor, p1_fitness, p2_fitness, gen, lookback, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks)\n\u001b[0;32m    160\u001b[0m ipop \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop, off])\n\u001b[0;32m    161\u001b[0m iskill_factor \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskill_factor, off_skill_factor])\n",
      "File \u001b[1;32md:\\PYTHON\\NCKH\\amfea\\rmp\\AdaptiveRMPMatrix.py:132\u001b[0m, in \u001b[0;36mAdaptiveRMPMatrix.__call__\u001b[1;34m(self, collect_state, p1, p2, p1_skill_factor, p2_skill_factor, p1_fitness, p2_fitness, gen, llm_rate, tasks)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, collect_state, p1, p2, p1_skill_factor, p2_skill_factor, p1_fitness, p2_fitness, gen, llm_rate, tasks):\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_rmp(collect_state, p1, p2, p1_skill_factor, p2_skill_factor, p1_fitness, p2_fitness, gen, llm_rate, tasks)\n",
      "File \u001b[1;32md:\\PYTHON\\NCKH\\amfea\\rmp\\AdaptiveRMPMatrix.py:111\u001b[0m, in \u001b[0;36mAdaptiveRMPMatrix.get_rmp\u001b[1;34m(self, collect_state, p1, p2, p1_skill_factor, p2_skill_factor, p1_fitness, p2_fitness, gen_mfea, lookback, tasks)\u001b[0m\n\u001b[0;32m    109\u001b[0m     off_strategy \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mreverse(off_strategy)\n\u001b[0;32m    110\u001b[0m     reversed_individual \u001b[38;5;241m=\u001b[39m IndividualRMP(off_strategy)\n\u001b[1;32m--> 111\u001b[0m     individual_performance \u001b[38;5;241m=\u001b[39m reversed_individual\u001b[38;5;241m.\u001b[39mevaluate(collect_state, p1, p2, p1_skill_factor, p2_skill_factor, p1_fitness, p2_fitness, tasks)\n\u001b[0;32m    112\u001b[0m     off_list\u001b[38;5;241m.\u001b[39mappend(reversed_individual)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpm:\n",
      "File \u001b[1;32md:\\PYTHON\\NCKH\\amfea\\rmp\\AdaptiveRMPMatrix.py:42\u001b[0m, in \u001b[0;36mIndividualRMP.evaluate\u001b[1;34m(self, collect_state, p1, p2, p1_skill_factor, p2_skill_factor, p1_fitness, p2_fitness, tasks)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStrategy:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m rmp_function \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mstrategy_to_code(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMP function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmp_function\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\PYTHON\\NCKH\\amfea\\llm\\GPTModel.py:94\u001b[0m, in \u001b[0;36mGPTModel.strategy_to_code\u001b[1;34m(self, strategy)\u001b[0m\n\u001b[0;32m     92\u001b[0m strategy_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(strategy)\n\u001b[0;32m     93\u001b[0m create_prompt \u001b[38;5;241m=\u001b[39m create_text\u001b[38;5;241m.\u001b[39mformat(strategy_text\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m---> 94\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     95\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m     96\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     97\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: create_prompt},\n\u001b[0;32m     98\u001b[0m     ],\n\u001b[0;32m     99\u001b[0m     max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m,\n\u001b[0;32m    100\u001b[0m     temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature,\n\u001b[0;32m    101\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    102\u001b[0m )\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# print(response.choices[0].message.content)\u001b[39;00m\n\u001b[0;32m    105\u001b[0m code \u001b[38;5;241m=\u001b[39m clean_code_output(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    922\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    927\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    928\u001b[0m             {\n\u001b[0;32m    929\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    930\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    931\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m    932\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    933\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    934\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    935\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    936\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    937\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    938\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    939\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    940\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m    941\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    942\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    943\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m    944\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    945\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m    946\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    947\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    948\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    949\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    950\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    951\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    952\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    953\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    954\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    955\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    956\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    957\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    958\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    959\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m    960\u001b[0m             },\n\u001b[0;32m    961\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[0;32m    962\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m    963\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[0;32m    964\u001b[0m         ),\n\u001b[0;32m    965\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    966\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    967\u001b[0m         ),\n\u001b[0;32m    968\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    969\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    970\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    971\u001b[0m     )\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\openai\\_base_client.py:969\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    967\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    970\u001b[0m         request,\n\u001b[0;32m    971\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    972\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    973\u001b[0m     )\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    975\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    915\u001b[0m     request,\n\u001b[0;32m    916\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    917\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    918\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    919\u001b[0m )\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    943\u001b[0m         request,\n\u001b[0;32m    944\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    945\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    946\u001b[0m     )\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1011\u001b[0m     )\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    248\u001b[0m )\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    259\u001b[0m )\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[0;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    238\u001b[0m     )\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    100\u001b[0m     (\n\u001b[0;32m    101\u001b[0m         http_version,\n\u001b[0;32m    102\u001b[0m         status,\n\u001b[0;32m    103\u001b[0m         reason_phrase,\n\u001b[0;32m    104\u001b[0m         headers,\n\u001b[0;32m    105\u001b[0m         trailing_data,\n\u001b[1;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\ssl.py:1232\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1231\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bfs, mfs = amfea.fit(num_gen=1000,monitor=True, monitor_rate=100, llm_rate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f71a36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_tasks = len(tasks)\n",
    "# fig, axes = plt.subplots(num_tasks, 2)\n",
    "# fig.tight_layout()\n",
    "# for i in range(num_tasks):\n",
    "#     axes[i][0].plot(bfs[i])\n",
    "#     axes[i][1].plot(mfs[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
